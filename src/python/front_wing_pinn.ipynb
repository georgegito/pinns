{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics Informed Neural Networks <br> F1 Car Front Wing Aerodymanics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              x         y         z\n",
      "0      0.440148  0.073950  0.103123\n",
      "1      0.713695  0.209429  0.055195\n",
      "2      0.451790  0.021569  0.052462\n",
      "3      0.032607  0.154912  0.108069\n",
      "4      0.750952  0.139930  0.113273\n",
      "...         ...       ...       ...\n",
      "19995  0.913177  0.282509  0.051195\n",
      "19996  0.115440  0.221203  0.028832\n",
      "19997  0.453917  0.034118  0.052462\n",
      "19998  0.556022  0.063779  0.101915\n",
      "19999  0.030382  0.130567  0.011402\n",
      "\n",
      "[20000 rows x 3 columns]\n",
      "              x         y         z\n",
      "0     -1.000000 -0.000293 -0.000429\n",
      "1     -0.283259 -0.649111 -0.705988\n",
      "2      0.000000  0.000000 -1.000000\n",
      "3     -0.974604  0.223384  0.015692\n",
      "4     -0.325352 -0.933390  0.151428\n",
      "...         ...       ...       ...\n",
      "19995 -0.018169 -0.132277  0.991046\n",
      "19996 -0.991501 -0.031098 -0.126326\n",
      "19997  0.000000  0.000000 -1.000000\n",
      "19998  1.000000 -0.000293 -0.000429\n",
      "19999 -0.730616  0.157085 -0.664473\n",
      "\n",
      "[20000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "in_filepath = \"/Users/ggito/repos/pinns/data/\"\n",
    "points_filename = \"front_wing_points_final.csv\"\n",
    "norms_filename = \"front_wing_norms_final.csv\"\n",
    "\n",
    "wing_df = pd.read_csv(in_filepath + points_filename)\n",
    "norm_df = pd.read_csv(in_filepath + norms_filename)\n",
    "\n",
    "print(wing_df)\n",
    "print(norm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_log(log_filepath, total_loss, pde_loss, ic_loss, bc_loss, wing_loss):\n",
    "  new_row = {\n",
    "    \"total_loss\": total_loss.item(),\n",
    "    \"pde_loss\": pde_loss.item(),\n",
    "    \"ic_loss\": ic_loss.item(),\n",
    "    \"bc_loss\": bc_loss.item(),\n",
    "    \"wing_loss\": wing_loss.item()\n",
    "  }\n",
    "\n",
    "  with open(log_filepath, 'a', newline='') as file:\n",
    "      \n",
    "    writer = csv.DictWriter(file, fieldnames=new_row.keys())\n",
    "    \n",
    "    file.seek(0, 2)\n",
    "    if file.tell() == 0:\n",
    "      writer.writeheader()\n",
    "    \n",
    "    writer.writerow(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(x, y):\n",
    "  return torch.autograd.grad(x, y, grad_outputs=torch.ones_like(x), create_graph=True, retain_graph=True, only_inputs=True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "  def __init__(self, input_dim, output_dim, hidden_units):\n",
    "    super(PINN, self).__init__()\n",
    "    self.layers = nn.ModuleList()\n",
    "    in_units = input_dim\n",
    "    for units in hidden_units:\n",
    "      layer = nn.Linear(in_units, units)\n",
    "      nn.init.xavier_normal_(layer.weight)  # Apply Xavier initialization\n",
    "      self.layers.append(layer)\n",
    "      in_units = units\n",
    "    output_layer = nn.Linear(in_units, output_dim)\n",
    "    nn.init.xavier_normal_(output_layer.weight)  # Apply Xavier initialization\n",
    "    self.layers.append(output_layer)\n",
    "\n",
    "  def forward(self, input):\n",
    "    for layer in self.layers[:-1]:\n",
    "      # output = torch.sigmoid(layer(input))\n",
    "      output = torch.tanh(layer(input))\n",
    "      # output = torch.relu(layer(input))\n",
    "      input = output\n",
    "    output = self.layers[-1](input)\n",
    "    return output\n",
    "\n",
    "  def loss(self, \n",
    "        x_f, y_f, z_f, t_f, \n",
    "        x0, y0, z0, t0, \n",
    "        x_b, y_b, z_b, t_b,\n",
    "        x_w, y_w, z_w, t_w,\n",
    "        mu, rho, dt, c1, c2, c3, c4, log_filepath):\n",
    "\n",
    "    xyzt_combinations = torch.cartesian_prod(x_f.flatten(), y_f.flatten(), z_f.flatten(), t_f.flatten())\n",
    "    output = self(xyzt_combinations)\n",
    "    u = output[:, 0]\n",
    "    v = output[:, 1]\n",
    "    w = output[:, 2]\n",
    "    p = output[:, 3]\n",
    "\n",
    "    u_t = grad(u, t_f)\n",
    "    u_x = grad(u, x_f)\n",
    "    u_y = grad(u, y_f)\n",
    "    u_z = grad(u, z_f)\n",
    "    u_xx = grad(u_x, x_f)\n",
    "    u_yy = grad(u_y, y_f)\n",
    "    u_zz = grad(u_z, z_f)\n",
    "\n",
    "    v_t = grad(v, t_f)\n",
    "    v_x = grad(v, x_f)\n",
    "    v_y = grad(v, y_f)\n",
    "    v_z = grad(v, z_f)\n",
    "    v_xx = grad(v_x, x_f)\n",
    "    v_yy = grad(v_y, y_f)\n",
    "    v_zz = grad(v_z, z_f)\n",
    "\n",
    "    w_t = grad(w, t_f)\n",
    "    w_x = grad(w, x_f)\n",
    "    w_y = grad(w, y_f)\n",
    "    w_z = grad(w, z_f)\n",
    "    w_xx = grad(w_x, x_f)\n",
    "    w_yy = grad(w_y, y_f)\n",
    "    w_zz = grad(w_z, z_f)\n",
    "\n",
    "    p_x = grad(p, x_f)\n",
    "    p_xx = grad(p_x, x_f)\n",
    "    p_y = grad(p, y_f)\n",
    "    p_yy = grad(p_y, y_f)\n",
    "    p_z = grad(p, z_f)\n",
    "    p_zz = grad(p_z, z_f)\n",
    "\n",
    "    # b = rho * ( 1/dt * (u_x + v_y) - u_x**2 - 2*u_y*v_x - v_y**2)\n",
    "\n",
    "    f1 = u_t + u*u_x + v*u_y + w*u_z + (1/rho) * p_x - mu * (u_xx + u_yy + u_zz)\n",
    "    f2 = v_t + u*v_x + v*v_y + w*v_z + (1/rho) * p_y - mu * (v_xx + v_yy + v_zz)\n",
    "    f3 = w_t + u*w_x + v*w_y + w*w_z + (1/rho) * p_z - mu * (w_xx + w_yy + w_zz)\n",
    "    f3 = u_x + v_y + w_z\n",
    "    # TODO: add poisson equation & impermeability condition\n",
    "    # f4 = p_xx + p_yy + p_zz - b\n",
    "\n",
    "    # Initial condition loss\n",
    "    output_init = self(torch.cat([x0, y0, z0, t0], dim=1))\n",
    "    u0_pred = output_init[:, 0]\n",
    "    v0_pred = output_init[:, 1]\n",
    "    w0_pred = output_init[:, 2]\n",
    "    p0_pred = output_init[:, 3]\n",
    "\n",
    "    # for x > 0 and t = 0 -> u, v, p = 0\n",
    "\n",
    "    u0_true = torch.zeros_like(u0_pred)\n",
    "    v0_true = torch.zeros_like(v0_pred)\n",
    "    w0_true = torch.zeros_like(w0_pred)\n",
    "    p0_true = torch.ones_like(p0_pred)\n",
    "\n",
    "    ic_loss_u = torch.mean(torch.square(u0_pred - u0_true))\n",
    "    ic_loss_v = torch.mean(torch.square(v0_pred - v0_true))\n",
    "    ic_loss_w = torch.mean(torch.square(w0_pred - w0_true))\n",
    "    ic_loss_p = torch.mean(torch.square(p0_pred - p0_true))\n",
    "\n",
    "    # Boundary conditions loss\n",
    "\n",
    "    xyzt_combinations = torch.cartesian_prod(x_b.flatten(), y_b.flatten(), z_b.flatten(), t_b.flatten())\n",
    "    output_boundary = self(xyzt_combinations)\n",
    "    u_b_pred = output_boundary[:, 0]\n",
    "    v_b_pred = output_boundary[:, 1]\n",
    "    w_b_pred = output_boundary[:, 2]\n",
    "\n",
    "    # u = 1, v = 0 and w = 0 for x = 0\n",
    "\n",
    "    u_b_true = torch.ones_like(u_b_pred)\n",
    "    v_b_true = torch.zeros_like(v_b_pred)\n",
    "    w_b_true = torch.zeros_like(w_b_pred)\n",
    "    \n",
    "    bc_loss_u = torch.mean(torch.square(u_b_pred - u_b_true))\n",
    "    bc_loss_v = torch.mean(torch.square(v_b_pred - v_b_true))\n",
    "    bc_loss_w = torch.mean(torch.square(w_b_pred - w_b_true))\n",
    "\n",
    "    # Wing surface boundary conditions loss\n",
    "\n",
    "    xyzt_combinations = torch.cartesian_prod(x_w.flatten(), y_w.flatten(), z_w.flatten(), t_w.flatten())\n",
    "    output_wing = self(xyzt_combinations)\n",
    "    u_w_pred = output_wing[:, 0]\n",
    "    v_w_pred = output_wing[:, 1]\n",
    "    w_w_pred = output_wing[:, 2]\n",
    "\n",
    "    u_w_true = torch.zeros_like(u_w_pred)\n",
    "    v_w_true = torch.zeros_like(v_w_pred)\n",
    "    w_w_true = torch.zeros_like(w_w_pred)\n",
    "    \n",
    "    wing_loss_u = torch.mean(torch.square(u_w_pred - u_w_true))\n",
    "    wing_loss_v = torch.mean(torch.square(v_w_pred - v_w_true))\n",
    "    wing_loss_w = torch.mean(torch.square(w_w_pred - w_w_true))\n",
    "\n",
    "    # Combine PDE residual, initial condition, and boundary condition losses\n",
    "    pde_loss =  torch.mean(torch.square(f1)) + \\\n",
    "                torch.mean(torch.square(f2)) + \\\n",
    "                torch.mean(torch.square(f3)) / 3\n",
    "    \n",
    "    ic_loss = (ic_loss_u + ic_loss_v + ic_loss_p) / 3 \n",
    "    \n",
    "    bc_loss = (bc_loss_u + bc_loss_v + bc_loss_w) / 3\n",
    "\n",
    "    wing_loss = (wing_loss_u + wing_loss_v + wing_loss_w) / 3\n",
    "\n",
    "    total_loss =  c1 * pde_loss + \\\n",
    "                  c2 * ic_loss + \\\n",
    "                  c3 * bc_loss + \\\n",
    "                  c4 * wing_loss\n",
    "\n",
    "    save_log(log_filepath, total_loss, pde_loss, ic_loss, bc_loss, wing_loss)\n",
    "\n",
    "    return total_loss, pde_loss, ic_loss, bc_loss, wing_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_max = 1\n",
    "y_max = 1\n",
    "z_max = 1\n",
    "t_max = 1\n",
    "\n",
    "Nx = 10\n",
    "Ny = 10\n",
    "Nz = 10\n",
    "Nt = 10\n",
    "\n",
    "dx = x_max / (Nx - 1)\n",
    "dy = y_max / (Ny - 1)\n",
    "dz = z_max / (Nz - 1)\n",
    "dt = t_max / (Nt - 1)\n",
    "\n",
    "x_test = np.linspace(0, x_max, Nx)\n",
    "y_test = np.linspace(0, y_max, Ny)\n",
    "z_test = np.linspace(0, z_max, Nz)\n",
    "t_test = np.linspace(0, t_max, Nt)\n",
    "\n",
    "x_grid, y_grid, z_gripd, t_grid = np.meshgrid(x_test, y_test, z_test, t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "input_dim = 4\n",
    "output_dim = 4\n",
    "# hidden_units = [32, 32, 32]\n",
    "# hidden_units = [64, 64, 64, 64]\n",
    "# hidden_units = [128, 128, 128, 128]\n",
    "# hidden_units = [256, 256, 256, 256]\n",
    "# hidden_units = [512, 512]\n",
    "hidden_units = [1024, 1024, 1024]\n",
    "# hidden_units = [20, 40, 80, 100, 100, 80, 40, 20]\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "  device = torch.device(\"mps\")\n",
    "  x = torch.ones(1, device=device)\n",
    "  print (x)\n",
    "else:\n",
    "  print (\"MPS device not found.\")\n",
    "  device = \"cpu\"\n",
    "\n",
    "# device = \"cpu\"\n",
    "\n",
    "pinn = PINN(input_dim, output_dim, hidden_units).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(pinn.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.LBFGS(pinn.parameters())\n",
    "\n",
    "epochs = 1000\n",
    "Nf = Nx   # num of collocation points -> pde evaluation -> Nf^4... needs fixing: sample Nf points from the whole 3D domain\n",
    "N0 = Ny   # num of points to evaluate initial conditons -> N0^4\n",
    "Nb = Nx   # num of points to evaluate boundary conditions -> Nb^4\n",
    "Nw = Nx   # num of points of the surface of the front wing to evaluate boundary conditions -> Nw^4\n",
    "\n",
    "# Density (rho): 1.184 kg/mÂ³\n",
    "# Dynamic viscosity (mu): 1.81e-5 kg/m.s\n",
    "rho = 1184\n",
    "mu = 1.81e-5\n",
    "\n",
    "log_filepath = \"/Users/ggito/repos/pinns/data/log.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_points_in_domain(min, max, num_of_samples):\n",
    "  return torch.tensor(np.random.uniform(min, max, size=(num_of_samples, 1)), dtype=torch.float32, device=device, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeros(num):\n",
    "  return torch.zeros(size=(num, 1), dtype=torch.float32, device=device, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m total_loss\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 43\u001b[0m   \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m   \u001b[38;5;66;03m# if epoch % 10 == 0:\u001b[39;00m\n\u001b[1;32m     45\u001b[0m   total_loss, pde_loss, ic_loss, bc_loss, wing_loss \u001b[38;5;241m=\u001b[39m closure(report_losses\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/lbfgs.py:438\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_iter \u001b[38;5;241m!=\u001b[39m max_iter:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;66;03m# re-evaluate function only if not in last iteration\u001b[39;00m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;66;03m# the reason we do this: in a stochastic setting,\u001b[39;00m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;66;03m# no use to re-evaluate that function here\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 438\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    439\u001b[0m     flat_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather_flat_grad()\n\u001b[1;32m    440\u001b[0m     opt_cond \u001b[38;5;241m=\u001b[39m flat_grad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance_grad\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 26\u001b[0m, in \u001b[0;36mclosure\u001b[0;34m(report_losses)\u001b[0m\n\u001b[1;32m     23\u001b[0m x_w, y_w, z_w \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor(wing_df\u001b[38;5;241m.\u001b[39mloc[sampled_indices, col]\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mdevice, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     24\u001b[0m t_w \u001b[38;5;241m=\u001b[39m sample_points_in_domain(\u001b[38;5;241m0\u001b[39m, t_max, Nw)\n\u001b[0;32m---> 26\u001b[0m total_loss, pde_loss, ic_loss, bc_loss, wing_loss \u001b[38;5;241m=\u001b[39m \u001b[43mpinn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                \u001b[49m\u001b[43mx_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_f\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                \u001b[49m\u001b[43mx_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_b\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                \u001b[49m\u001b[43mx_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_w\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m0.005\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlog_filepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m total_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m report_losses:\n",
      "Cell \u001b[0;32mIn[6], line 46\u001b[0m, in \u001b[0;36mPINN.loss\u001b[0;34m(self, x_f, y_f, z_f, t_f, x0, y0, z0, t0, x_b, y_b, z_b, t_b, x_w, y_w, z_w, t_w, mu, rho, dt, c1, c2, c3, c4, log_filepath)\u001b[0m\n\u001b[1;32m     43\u001b[0m u_yy \u001b[38;5;241m=\u001b[39m grad(u_y, y_f)\n\u001b[1;32m     44\u001b[0m u_zz \u001b[38;5;241m=\u001b[39m grad(u_z, z_f)\n\u001b[0;32m---> 46\u001b[0m v_t \u001b[38;5;241m=\u001b[39m \u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_f\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m v_x \u001b[38;5;241m=\u001b[39m grad(v, x_f)\n\u001b[1;32m     48\u001b[0m v_y \u001b[38;5;241m=\u001b[39m grad(v, y_f)\n",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad\u001b[39m(x, y):\n\u001b[0;32m----> 2\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/__init__.py:394\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    390\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    391\u001b[0m         grad_outputs_\n\u001b[1;32m    392\u001b[0m     )\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 394\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    404\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    405\u001b[0m         output\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros_like(\u001b[38;5;28minput\u001b[39m, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (output, \u001b[38;5;28minput\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(result, t_inputs)\n\u001b[1;32m    409\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def closure(report_losses=False):\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  # TODO: use quasi monte carlo sampling\n",
    "  z_f = sample_points_in_domain(0, x_max, Nf)\n",
    "  y_f = sample_points_in_domain(0, y_max, Nf)\n",
    "  x_f = sample_points_in_domain(0, z_max, Nf)\n",
    "  t_f = sample_points_in_domain(0, t_max, Nf)\n",
    "\n",
    "  x0 = sample_points_in_domain(dx, x_max, N0)\n",
    "  y0 = sample_points_in_domain(dy, y_max, N0)\n",
    "  z0 = sample_points_in_domain(dz, z_max, N0)\n",
    "  t0 = sample_points_in_domain(0, t_max, N0)\n",
    "\n",
    "  x_b = zeros(Nb)\n",
    "  y_b = sample_points_in_domain(0, y_max, Nb)\n",
    "  z_b = sample_points_in_domain(0, z_max, Nb)\n",
    "  t_b = sample_points_in_domain(0, t_max, Nb)\n",
    "  \n",
    "  # sample Nw wing points\n",
    "  sampled_indices = wing_df.sample(n=Nw).index\n",
    "\n",
    "  x_w, y_w, z_w = [torch.tensor(wing_df.loc[sampled_indices, col].values, dtype=torch.float32, device=device, requires_grad=True) for col in ['x', 'y', 'z']]\n",
    "  t_w = sample_points_in_domain(0, t_max, Nw)\n",
    "\n",
    "  total_loss, pde_loss, ic_loss, bc_loss, wing_loss = pinn.loss(\n",
    "                  x_f, y_f, z_f, t_f,\n",
    "                  x0, y0, z0, t0,\n",
    "                  x_b, y_b, z_b, t_b,\n",
    "                  x_w, y_w, z_w, t_w,\n",
    "                  mu, rho, dt,\n",
    "                  0.005, 0.25, 0.25, 0.25,\n",
    "                  log_filepath)\n",
    "\n",
    "  total_loss.backward()\n",
    "\n",
    "  if report_losses:\n",
    "      return total_loss, pde_loss, ic_loss, bc_loss, wing_loss\n",
    "  else:\n",
    "      return total_loss\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  optimizer.step(closure)\n",
    "  # if epoch % 10 == 0:\n",
    "  total_loss, pde_loss, ic_loss, bc_loss, wing_loss = closure(report_losses=True)\n",
    "  print(f'Epoch: {epoch},\\tTotal loss: {total_loss.item()},\\tPDE loss: {pde_loss.item()},\\tIC loss: {ic_loss.item()},\\tBC loss: {bc_loss.item()},\\tWing loss: {wing_loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
