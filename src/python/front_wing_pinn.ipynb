{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics Informed Neural Networks <br> F1 Car Front Wing Aerodymanics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              x         y         z\n",
      "0      0.440148  0.073950  0.103123\n",
      "1      0.713695  0.209429  0.055195\n",
      "2      0.451790  0.021569  0.052462\n",
      "3      0.032607  0.154912  0.108069\n",
      "4      0.750952  0.139930  0.113273\n",
      "...         ...       ...       ...\n",
      "19995  0.913177  0.282509  0.051195\n",
      "19996  0.115440  0.221203  0.028832\n",
      "19997  0.453917  0.034118  0.052462\n",
      "19998  0.556022  0.063779  0.101915\n",
      "19999  0.030382  0.130567  0.011402\n",
      "\n",
      "[20000 rows x 3 columns]\n",
      "              x         y         z\n",
      "0     -1.000000 -0.000293 -0.000429\n",
      "1     -0.283259 -0.649111 -0.705988\n",
      "2      0.000000  0.000000 -1.000000\n",
      "3     -0.974604  0.223384  0.015692\n",
      "4     -0.325352 -0.933390  0.151428\n",
      "...         ...       ...       ...\n",
      "19995 -0.018169 -0.132277  0.991046\n",
      "19996 -0.991501 -0.031098 -0.126326\n",
      "19997  0.000000  0.000000 -1.000000\n",
      "19998  1.000000 -0.000293 -0.000429\n",
      "19999 -0.730616  0.157085 -0.664473\n",
      "\n",
      "[20000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "in_filepath = \"/Users/ggito/repos/pinns/data/\"\n",
    "points_filename = \"front_wing_points_final.csv\"\n",
    "norms_filename = \"front_wing_norms_final.csv\"\n",
    "\n",
    "wing_df = pd.read_csv(in_filepath + points_filename)\n",
    "norm_df = pd.read_csv(in_filepath + norms_filename)\n",
    "\n",
    "print(wing_df)\n",
    "print(norm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_units):\n",
    "        super(PINN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        in_units = input_dim\n",
    "        for units in hidden_units:\n",
    "            layer = nn.Linear(in_units, units)\n",
    "            nn.init.xavier_normal_(layer.weight)  # Apply Xavier initialization\n",
    "            self.layers.append(layer)\n",
    "            in_units = units\n",
    "        output_layer = nn.Linear(in_units, output_dim)\n",
    "        nn.init.xavier_normal_(output_layer.weight)  # Apply Xavier initialization\n",
    "        self.layers.append(output_layer)\n",
    "\n",
    "    def forward(self, input):\n",
    "        for layer in self.layers[:-1]:\n",
    "            output = torch.tanh(layer(input))\n",
    "            input = output\n",
    "        output = self.layers[-1](input)\n",
    "        return output\n",
    "\n",
    "    def loss(self, x_f, y_f, z_f, t_f, x0, y0, z0, t0, x_b, y_b, z_b, t_b,\n",
    "             mu, rho, dt, c1, c2, c3, c4):\n",
    "\n",
    "        xyzt_combinations = torch.cartesian_prod(x_f.flatten(), y_f.flatten(), z_f.flatten(), t_f.flatten())\n",
    "        output = self(xyzt_combinations)\n",
    "        u = output[:, 0]\n",
    "        v = output[:, 1]\n",
    "        w = output[:, 2]\n",
    "        p = output[:, 3]\n",
    "\n",
    "        u_t = torch.autograd.grad(u, t_f, grad_outputs=torch.ones_like(u), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        u_x = torch.autograd.grad(u, x_f, grad_outputs=torch.ones_like(u), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        u_y = torch.autograd.grad(u, y_f, grad_outputs=torch.ones_like(u), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        u_z = torch.autograd.grad(u, z_f, grad_outputs=torch.ones_like(u), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        u_xx = torch.autograd.grad(u_x, x_f, grad_outputs=torch.ones_like(u_x), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        u_yy = torch.autograd.grad(u_y, y_f, grad_outputs=torch.ones_like(u_y), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        u_zz = torch.autograd.grad(u_z, z_f, grad_outputs=torch.ones_like(u_z), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "        v_t = torch.autograd.grad(v, t_f, grad_outputs=torch.ones_like(v), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        v_x = torch.autograd.grad(v, x_f, grad_outputs=torch.ones_like(v), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        v_y = torch.autograd.grad(v, y_f, grad_outputs=torch.ones_like(v), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        v_z = torch.autograd.grad(v, z_f, grad_outputs=torch.ones_like(v), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        v_xx = torch.autograd.grad(v_x, x_f, grad_outputs=torch.ones_like(v_x), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        v_yy = torch.autograd.grad(v_y, y_f, grad_outputs=torch.ones_like(v_y), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        v_zz = torch.autograd.grad(v_z, z_f, grad_outputs=torch.ones_like(v_z), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "        w_t = torch.autograd.grad(w, t_f, grad_outputs=torch.ones_like(w), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        w_x = torch.autograd.grad(w, x_f, grad_outputs=torch.ones_like(w), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        w_y = torch.autograd.grad(w, y_f, grad_outputs=torch.ones_like(w), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        w_z = torch.autograd.grad(w, z_f, grad_outputs=torch.ones_like(w), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        w_xx = torch.autograd.grad(w_x, x_f, grad_outputs=torch.ones_like(w_x), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        w_yy = torch.autograd.grad(w_y, y_f, grad_outputs=torch.ones_like(w_y), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        w_zz = torch.autograd.grad(w_z, z_f, grad_outputs=torch.ones_like(w_z), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "        p_x = torch.autograd.grad(p, x_f, grad_outputs=torch.ones_like(p), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        p_xx = torch.autograd.grad(p_x, x_f, grad_outputs=torch.ones_like(p_x), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        p_y = torch.autograd.grad(p, y_f, grad_outputs=torch.ones_like(p), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        p_yy = torch.autograd.grad(p_y, y_f, grad_outputs=torch.ones_like(p_y), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        p_z = torch.autograd.grad(p, z_f, grad_outputs=torch.ones_like(p), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        p_zz = torch.autograd.grad(p_z, z_f, grad_outputs=torch.ones_like(p_z), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "        # b = rho * ( 1/dt * (u_x + v_y) - u_x**2 - 2*u_y*v_x - v_y**2)\n",
    "\n",
    "        f1 = u_t + u*u_x + v*u_y + w*u_z + (1/rho) * p_x - mu * (u_xx + u_yy + u_zz)\n",
    "        f2 = v_t + u*v_x + v*v_y + w*v_z + (1/rho) * p_y - mu * (v_xx + v_yy + v_zz)\n",
    "        f3 = w_t + u*w_x + v*w_y + w*w_z + (1/rho) * p_z - mu * (w_xx + w_yy + w_zz)\n",
    "        f3 = u_x + v_y + w_z\n",
    "        # TODO: add poisson equation & impermeability condition\n",
    "        # f4 = p_xx + p_yy + p_zz - b\n",
    "\n",
    "        # Initial condition loss\n",
    "        output_init = self(torch.cat([x0, y0, z0, t0], dim=1))\n",
    "        u0_pred = output_init[:, 0]\n",
    "        v0_pred = output_init[:, 1]\n",
    "        w0_pred = output_init[:, 2]\n",
    "        p0_pred = output_init[:, 3]\n",
    "\n",
    "        # for x > 0 and t = 0 -> u, v, p = 0\n",
    "\n",
    "        u0_true = torch.zeros_like(u0_pred)\n",
    "        v0_true = torch.zeros_like(v0_pred)\n",
    "        w0_true = torch.zeros_like(w0_pred)\n",
    "        p0_true = torch.ones_like(p0_pred)\n",
    "\n",
    "        ic_loss_u = torch.mean(torch.square(u0_pred - u0_true))\n",
    "        ic_loss_v = torch.mean(torch.square(v0_pred - v0_true))\n",
    "        ic_loss_w = torch.mean(torch.square(w0_pred - w0_true))\n",
    "        ic_loss_p = torch.mean(torch.square(p0_pred - p0_true))\n",
    "\n",
    "        # Boundary conditions loss\n",
    "\n",
    "        xyzt_combinations = torch.cartesian_prod(x_b.flatten(), y_b.flatten(), z_b.flatten(), t_b.flatten())\n",
    "        output_boundary = self(xyt_combinations)\n",
    "        u_b_pred = output_boundary[:, 0]\n",
    "        v_b_pred = output_boundary[:, 1]\n",
    "        w_b_pred = output_boundary[:, 2]\n",
    "\n",
    "        # u = 1, v = 0 and w = 0 for x = 0\n",
    "\n",
    "        u_b_true = torch.ones_like(u_b_pred)\n",
    "        v_b_true = torch.zeros_like(v_b_pred)\n",
    "        w_b_true = torch.zeros_like(w_b_pred)\n",
    "        \n",
    "        bc_loss_u = torch.mean(torch.square(u_b_pred - u_b_true))\n",
    "        bc_loss_v = torch.mean(torch.square(v_b_pred - v_b_true))\n",
    "        bc_loss_w = torch.mean(torch.square(w_b_pred - w_b_true))\n",
    "\n",
    "\n",
    "        # TODO: wing surface boundary conditions loss\n",
    "        # ## down\n",
    "        # xyt_combinations = torch.cartesian_prod(x_box_down.flatten(), y_box_down.flatten(), t_box.flatten())\n",
    "        # output_boundary_box_down = self(xyt_combinations)\n",
    "        # u_box_down_pred = output_boundary_box_down[:, 0]\n",
    "        # v_box_down_pred = output_boundary_box_down[:, 1]\n",
    "\n",
    "        # u_box_down_true = torch.ones_like(u_box_down_pred)\n",
    "        # v_box_down_true = torch.zeros_like(v_box_down_pred)\n",
    "        \n",
    "        # box_down_loss_u = torch.mean(torch.square(u_box_down_pred - u_box_down_true))\n",
    "        # box_down_loss_v = torch.mean(torch.square(v_box_down_pred - v_box_down_true))\n",
    "\n",
    "        # Combine PDE residual, initial condition, and boundary condition losses\n",
    "        pde_loss =  torch.mean(torch.square(f1)) + \\\n",
    "                    torch.mean(torch.square(f2)) + \\\n",
    "                    torch.mean(torch.square(f3)) / 3\n",
    "        \n",
    "        ic_loss = (ic_loss_u + ic_loss_v + ic_loss_p) / 3 \n",
    "        \n",
    "        bc_loss = (bc_loss_u + bc_loss_v) / 2\n",
    "\n",
    "        # bc_box_loss = (box_left_loss_u + box_left_loss_v + \\\n",
    "        #                 box_up_loss_u + box_up_loss_v + \\\n",
    "        #                 box_right_loss_u + box_right_loss_v + \\\n",
    "        #                 box_down_loss_u + box_down_loss_v) / 8\n",
    "        \n",
    "        # bc_box_loss = torch.tensor(0)\n",
    "\n",
    "        # bc_box_loss = (box_left_loss_u + box_left_loss_v) / 2\n",
    "\n",
    "        total_loss =    c1 * pde_loss + \\\n",
    "                        c2 * ic_loss + \\\n",
    "                        c3 * bc_loss\n",
    "                        # c4 * bc_box_loss\n",
    "\n",
    "        return total_loss, pde_loss, ic_loss, bc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_uniform_domains(n_samples, domains):\n",
    "    samples = np.concatenate([np.random.uniform(low, high, n_samples) for low, high in domains])\n",
    "    return samples.reshape(-1, 1)\n",
    "\n",
    "def domains_union(domains, dx, reshape=True):\n",
    "    samples = np.concatenate([np.arange(low, high, dx) for low, high in domains])\n",
    "    \n",
    "    if reshape:\n",
    "        return samples.reshape(-1, 1)\n",
    "    else:\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_max = 1\n",
    "y_max = 1\n",
    "z_max = 1\n",
    "t_max = 1\n",
    "\n",
    "Nx = 30\n",
    "Ny = 30\n",
    "Nz = 30\n",
    "Nt = 10\n",
    "\n",
    "dx = x_max / (Nx - 1)\n",
    "dy = y_max / (Ny - 1)\n",
    "dz = z_max / (Nz - 1)\n",
    "dt = t_max / (Nt - 1)\n",
    "\n",
    "x_test = np.linspace(0, x_max, Nx)\n",
    "# x_test = domains_union([(0, 0.3), (0.7, x_max)], dx)\n",
    "y_test = np.linspace(0, y_max, Ny)\n",
    "# y_test = domains_union([(0, 0.3), (0.7, y_max)], dy)\n",
    "z_test = np.linspace(0, z_max, Nz)\n",
    "t_test = np.linspace(0, t_max, Nt)\n",
    "\n",
    "x_grid, y_grid, z_gripd, t_grid = np.meshgrid(x_test, y_test, z_test, t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mps_device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m     12\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[43mmps_device\u001b[49m)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m (x)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mps_device' is not defined"
     ]
    }
   ],
   "source": [
    "input_dim = 4\n",
    "output_dim = 4\n",
    "# hidden_units = [32, 32, 32]\n",
    "# hidden_units = [64, 64, 64, 64]\n",
    "# hidden_units = [128, 128, 128, 128]\n",
    "hidden_units = [256, 256, 256, 256]\n",
    "# hidden_units = [512, 512]\n",
    "# hidden_units = [1024, 1024, 1024]\n",
    "# hidden_units = [20, 40, 80, 100, 100, 80, 40, 20]\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "    device = \"cpu\"\n",
    "\n",
    "pinn = PINN(input_dim, output_dim, hidden_units).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(pinn.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.LBFGS(pinn.parameters())\n",
    "\n",
    "epochs = 1000\n",
    "# Nf = int(Nx / 10)   # num of collocation points -> pde evaluation -> Nf^3... needs fixing: sample Nf points from the whole 3D domain\n",
    "Nf = Nx   # num of collocation points -> pde evaluation -> Nf^3... needs fixing: sample Nf points from the whole 3D domain\n",
    "N0 = Ny    # num of points to evaluate initial conditons\n",
    "# Nb = int(Nx / 10)    # num of points to evaluate boundary conditions -> Nb^3... needs fixing: sample Nf points from the whole 3D domain\n",
    "Nb = Nx    # num of points to evaluate boundary conditions -> Nb^3... needs fixing: sample Nf points from the whole 3D domain\n",
    "# Nbox = 30  # num of points to evaluate boundary condition at each edge of the box\n",
    "\n",
    "# Density (rho): 1.184 kg/m³\n",
    "# Dynamic viscosity (mu): 1.81e-5 kg/m.s\n",
    "rho = 1184\n",
    "mu = 1.81e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def closure(report_losses=False):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    x_f = torch.tensor(random_uniform_domains(Nf, [(0, x_max)]), dtype=torch.float32, device=device, requires_grad=True) # collocation points\n",
    "    y_f = torch.tensor(random_uniform_domains(Nf, [(0, y_max)]), dtype=torch.float32, device=device, requires_grad=True) # collocation points\n",
    "    z_f = torch.tensor(random_uniform_domains(Nf, [(0, z_max)]), dtype=torch.float32, device=device, requires_grad=True) # collocation points\n",
    "    t_f = torch.tensor(np.random.uniform(0, t_max, size=(Nf, 1)), dtype=torch.float32, device=device, requires_grad=True) # collocation points\n",
    "\n",
    "    # TODO investigate\n",
    "    x0 = torch.tensor(np.random.uniform(dx, x_max, size=(N0, 1)), dtype=torch.float32, device=device, requires_grad=True)\n",
    "    y0 = torch.tensor(np.random.uniform(dy, y_max, size=(N0, 1)), dtype=torch.float32, device=device, requires_grad=True) \n",
    "    z0 = torch.tensor(np.random.uniform(dz, z_max, size=(N0, 1)), dtype=torch.float32, device=device, requires_grad=True) \n",
    "    t0 = torch.zeros_like(x0)\n",
    "    # t0 = torch.zeros(domains_union([(dt, t_max)], dt), dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "    x_b = torch.zeros(size=(Nb, 1), dtype=torch.float32, device=device, requires_grad=True)\n",
    "    y_b = torch.tensor(np.random.uniform(0, y_max, size=(Nb, 1)), dtype=torch.float32, device=device, requires_grad=True)\n",
    "    z_b = torch.tensor(np.random.uniform(0, z_max, size=(Nb, 1)), dtype=torch.float32, device=device, requires_grad=True)\n",
    "    t_b = torch.tensor(np.random.uniform(0, t_max, size=(Nb, 1)), dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "    total_loss, pde_loss, ic_loss, bc_loss = pinn.loss(\n",
    "                    x_f, y_f, z_f, t_f, x0, y0, z0, t0, x_b, y_b, z_b, t_b, \n",
    "                    mu, rho, dt, 0.005, 0.25, 0.25, 0.25)\n",
    "\n",
    "    total_loss.backward()\n",
    "\n",
    "    if report_losses:\n",
    "        return total_loss, pde_loss, ic_loss, bc_loss\n",
    "    else:\n",
    "        return total_loss\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.step(closure)\n",
    "    if epoch % 10 == 0:\n",
    "        total_loss, pde_loss, ic_loss, bc_loss = closure(report_losses=True)\n",
    "        print(f'Epoch: {epoch},\\tTotal loss: {total_loss.item()},\\tPDE loss: {pde_loss.item()},\\tIC loss: {ic_loss.item()},\\tBC loss: {bc_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
