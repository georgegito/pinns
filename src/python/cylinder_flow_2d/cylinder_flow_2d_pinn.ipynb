{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN for flow around a cylinder\n",
    "The Navier-Stokes equations are being solved for incompressible flow around a cylinder. These equations are a set of partial differential equations (PDEs) governing the motion of fluid substances. For a 2D incompressible, viscous flow, they can be written in the Cartesian coordinate system as follows:\n",
    "\n",
    "## Continuity Equation:\n",
    "\n",
    "The continuity equation represents the conservation of mass, stating that the mass entering a control volume must equal the mass exiting the volume, plus any change in mass within the volume. For an incompressible flow, it simplifies to:\n",
    "\n",
    "$$ \\nabla u = 0 $$\n",
    "\n",
    "or, in a two-dimensional form:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{\\partial u}{\\partial x} + \\frac{\\partial v}{\\partial y} = 0\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where u and v are the velocity components in the x and y directions respectively.\n",
    "\n",
    "## Momentum Equations:\n",
    "\n",
    "The momentum equations represent the conservation of momentum. They are the result of applying Newton's second law (force equals the rate of change of momentum) to fluid motion. The Navier-Stokes equations include the effects of viscosity, which are modeled with a Laplacian operator. The momentum equations for an incompressible flow can be written as:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\rho \\left( \\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x} + v \\frac{\\partial u}{\\partial y} \\right) = -\\frac{\\partial p}{\\partial x} + \\nu \\nabla^2 u\n",
    "\\tag{2}\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\rho \\left( \\frac{\\partial v}{\\partial t} + u \\frac{\\partial v}{\\partial x} + v \\frac{\\partial v}{\\partial y} \\right) = -\\frac{\\partial p}{\\partial y} + \\nu \\nabla^2 v\n",
    "\\tag{3}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "ρ is the fluid density\n",
    "u, v are the velocity components in the x and y directions, respectively\n",
    "t is time\n",
    "p is pressure\n",
    "ν is the kinematic viscosity\n",
    "∇² is the Laplacian operator, denoting the divergence of the gradient of a scalar field, here used to represent the diffusion of momentum (due to viscosity)\n",
    "The pressure-Poisson equation is also used to enforce incompressibility:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\nabla^2 p = -\\rho \\left[ \\left( \\frac{\\partial (u^2)}{\\partial x} + \\frac{\\partial (uv)}{\\partial y} \\right) + \\left( \\frac{\\partial (uv)}{\\partial x} + \\frac{\\partial (v^2)}{\\partial y} \\right) \\right]\n",
    "\\tag{4}\n",
    "\\end{equation}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\nabla^2 p = \\frac{\\partial^2 p}{\\partial x^2} + \\frac{\\partial^2 p}{\\partial y^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmax = 1.0\n",
    "ymax = 1.0\n",
    "tmax = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 1\n",
    "mu = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cylinder\n",
    "center = [0.5, 0.5]  # center of the cylinder\n",
    "radius = 0.1  # radius of the cylinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad(x, y):\n",
    "        return torch.autograd.grad(x, y, grad_outputs=torch.ones_like(x), create_graph=True, retain_graph=True, only_inputs=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collocation_points(xmin, xmax, ymin, ymax, tmin, tmax, center, radius, n):\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    t = []\n",
    "\n",
    "    h, k = center  # center of the circle\n",
    "\n",
    "    while len(x) < n:  # generate Nf points\n",
    "        # Generate random point in the rectangle\n",
    "        x_point = xmin + (xmax - xmin) * random.random()\n",
    "        y_point = ymin + (ymax - ymin) * random.random()\n",
    "        t_point = tmin + (tmax - tmin) * random.random()\n",
    "        \n",
    "        # Check if point is outside the circle\n",
    "        if (x_point - h) ** 2 + (y_point - k) ** 2 >= radius ** 2:\n",
    "            x.append(x_point)\n",
    "            y.append(y_point)\n",
    "            t.append(t_point)\n",
    "    return x, y, t\n",
    "\n",
    "def get_boundary_points(xmin, xmax, tmin, tmax, n):\n",
    "    \n",
    "    x = []\n",
    "    t = []\n",
    "\n",
    "    while len(x) < n:  # generate Nb points\n",
    "    # Generate random point in the rectangle\n",
    "        x_point = xmin + (xmax - xmin) * random.random()\n",
    "        t_point = tmin + (tmax - tmin) * random.random()\n",
    "        \n",
    "        x.append(x_point)\n",
    "        t.append(t_point)\n",
    "\n",
    "    return x, t\n",
    "\n",
    "def get_cylinder_bc_points(center, radius, tmin, tmax, n):\n",
    "\n",
    "    x_center, y_center = center\n",
    "    x = []\n",
    "    y = []\n",
    "    t = []\n",
    "    \n",
    "    for _ in range(n):\n",
    "        # Generate random angle and random radius\n",
    "        rand_angle = 2 * math.pi * random.random()\n",
    "        rand_radius = radius * math.sqrt(random.random())\n",
    "        # Convert polar coordinates to cartesian\n",
    "        x_point = x_center + rand_radius * math.cos(rand_angle)\n",
    "        y_point = y_center + rand_radius * math.sin(rand_angle)\n",
    "        t_point = tmin + (tmax - tmin) * random.random()\n",
    "\n",
    "        # Append to the lists\n",
    "        x.append(x_point)\n",
    "        y.append(y_point)\n",
    "        t.append(t_point)\n",
    "\n",
    "    return x, y, t\n",
    "\n",
    "def get_initial_points(xmin, xmax, ymin, ymax, n):\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    while len(x) < n:\n",
    "    # Generate random point in the rectangle\n",
    "        x_point = xmin + (xmax - xmin) * random.random()\n",
    "        y_point = ymin + (ymax - ymin) * random.random()\n",
    "        \n",
    "        x.append(x_point)\n",
    "        y.append(y_point)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_u_data(indices_to_extract, dir_path, Nt):\n",
    "\n",
    "    # Dictionary to store the results\n",
    "    result_dict = {}\n",
    "\n",
    "    for time_step in range(Nt):\n",
    "        file_path = dir_path + \"/u_\" + str(time_step) + \".csv\"\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            result_dict[file_path] = [df.iloc[i, j] for i, j in indices_to_extract]\n",
    "        else: \n",
    "            print(\"error\")\n",
    "            exit()\n",
    "\n",
    "    u_data = []\n",
    "\n",
    "    for file_path, values in result_dict.items():\n",
    "        u_data.append(values)\n",
    "\n",
    "    return np.array(u_data)\n",
    "\n",
    "def get_v_data(indices_to_extract, dir_path, Nt):\n",
    "\n",
    "    # Dictionary to store the results\n",
    "    result_dict = {}\n",
    "\n",
    "    for time_step in range(Nt):\n",
    "        file_path = dir_path + \"/v_\" + str(time_step) + \".csv\"\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            result_dict[file_path] = [df.iloc[i, j] for i, j in indices_to_extract]\n",
    "        else: \n",
    "            print(\"error\")\n",
    "            exit()\n",
    "\n",
    "    v_data = []\n",
    "\n",
    "    for file_path, values in result_dict.items():\n",
    "        v_data.append(values)\n",
    "\n",
    "    return np.array(v_data)\n",
    "\n",
    "def get_p_data(indices_to_extract, dir_path, Nt):\n",
    "\n",
    "    # Dictionary to store the results\n",
    "    result_dict = {}\n",
    "\n",
    "    for time_step in range(Nt):\n",
    "        file_path = dir_path + \"/p_\" + str(time_step) + \".csv\"\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            result_dict[file_path] = [df.iloc[i, j] for i, j in indices_to_extract]\n",
    "        else: \n",
    "            print(\"error\")\n",
    "            exit()\n",
    "\n",
    "    p_data = []\n",
    "\n",
    "    for file_path, values in result_dict.items():\n",
    "        p_data.append(values)\n",
    "\n",
    "    return np.array(p_data)\n",
    "\n",
    "def get_data_coords(data_indeces, dx, dy):\n",
    "\n",
    "    coords = []\n",
    "\n",
    "    for x_index, y_index in data_indeces:\n",
    "        coords.append([x_index * dx, y_index * dy])\n",
    "\n",
    "    return coords\n",
    "\n",
    "def get_timestamps(Nt, dt):\n",
    "\n",
    "    timestamps = []\n",
    "\n",
    "    for timestep in range(Nt):\n",
    "        timestamps.append(timestep * dt)\n",
    "\n",
    "    return np.array(timestamps)\n",
    "\n",
    "def get_training_data_batch(all_training_inputs, all_training_outputs, Nu):\n",
    "\n",
    "    selected_indeces = random.sample(range(len(all_training_inputs)), Nu)\n",
    "\n",
    "    inputs = all_training_inputs[selected_indeces, :]\n",
    "    outputs = all_training_outputs[selected_indeces, :]\n",
    "\n",
    "    x = inputs[:, 0]\n",
    "    y = inputs[:, 1]\n",
    "    t = inputs[:, 2]\n",
    "\n",
    "    u = outputs[:, 0]\n",
    "    v = outputs[:, 1]\n",
    "    p = outputs[:, 2]\n",
    "\n",
    "    return x, y, t, u, v, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specified indices to extract\n",
    "# 100 points * 1,000 timestamps = 100,000 samples\n",
    "data_indeces = [(10, 50), (10, 10), (50, 50), (50, 10)] # 0-based\n",
    "\n",
    "_x = 10\n",
    "for _y in range(0, 64, 4):\n",
    "    data_indeces.append((_x, _y))\n",
    "\n",
    "_x = 20\n",
    "for _y in range(0, 64, 4):\n",
    "    data_indeces.append((_x, _y))\n",
    "\n",
    "_x = 30\n",
    "for _y in range(0, 64, 4):\n",
    "    data_indeces.append((_x, _y))\n",
    "\n",
    "_x = 40\n",
    "for _y in range(0, 64, 4):\n",
    "    data_indeces.append((_x, _y))\n",
    "\n",
    "_x = 50\n",
    "for _y in range(0, 64, 4):\n",
    "    data_indeces.append((_x, _y))\n",
    "\n",
    "_x = 60\n",
    "for _y in range(0, 64, 4):\n",
    "    data_indeces.append((_x, _y))\n",
    "\n",
    "# Directory containing the CSV files\n",
    "u_data_dir_path = 'C:/Users/gitop/repos/pinns/src/python/cylinder_flow_2d/csv_files/u'\n",
    "v_data_dir_path = 'C:/Users/gitop/repos/pinns/src/python/cylinder_flow_2d/csv_files/v'\n",
    "p_data_dir_path = 'C:/Users/gitop/repos/pinns/src/python/cylinder_flow_2d/csv_files/p'\n",
    "\n",
    "# Number of timesteps\n",
    "Nt = 1000\n",
    "\n",
    "xmax = 1.0\n",
    "ymax = 1.0\n",
    "tmax = 0.1\n",
    "\n",
    "Nx = 64\n",
    "Ny = 64\n",
    "Nt = 1000\n",
    "\n",
    "dx = xmax / (Nx - 1)\n",
    "dy = ymax / (Ny - 1)\n",
    "dt = tmax / (Nt - 1)\n",
    "\n",
    "def load_training_data():\n",
    "\n",
    "    u_data = get_u_data(data_indeces, u_data_dir_path, Nt)\n",
    "    v_data = get_v_data(data_indeces, v_data_dir_path, Nt)\n",
    "    p_data = get_p_data(data_indeces, p_data_dir_path, Nt)\n",
    "\n",
    "    # Compute means and standard deviations\n",
    "    u_mean, u_std = u_data.mean(), u_data.std()\n",
    "    v_mean, v_std = v_data.mean(), v_data.std()\n",
    "    p_mean, p_std = p_data.mean(), p_data.std()\n",
    "\n",
    "    # Normalize the data\n",
    "    u_data_normalized = (u_data - u_mean) / u_std\n",
    "    v_data_normalized = (v_data - v_mean) / v_std\n",
    "    p_data_normalized = (p_data - p_mean) / p_std\n",
    "\n",
    "    data_coords = get_data_coords(data_indeces, dx, dy)\n",
    "    timestamps = get_timestamps(Nt, dt)\n",
    "\n",
    "    inputs = []\n",
    "\n",
    "    for t in timestamps:\n",
    "        for x, y in data_coords:\n",
    "            inputs.append([x, y, t])\n",
    "\n",
    "    inputs = np.array(inputs)\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    for t in range(Nt):\n",
    "        for i in range(len(data_coords)):\n",
    "            outputs.append([u_data_normalized[t, i], v_data_normalized[t, i], p_data_normalized[t, i]])\n",
    "\n",
    "    outputs = np.array(outputs)\n",
    "\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training_inputs, all_training_outputs = load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(Nf, Nc, Nb, Nu, Ni):\n",
    "\n",
    "    xf, yf, tf = get_collocation_points(0, xmax, 0, ymax, 0, tmax, center, radius, Nf)\n",
    "    xc, yc, tc = get_cylinder_bc_points(center, radius, 0, tmax, Nc)\n",
    "\n",
    "    xb_left = np.zeros(int(Nb/4))\n",
    "    yb_left, tb_left = get_boundary_points(0, ymax, 0, tmax, int(Nb/4))\n",
    "\n",
    "    xb_right = np.ones(int(Nb/4))\n",
    "    yb_right, tb_right = get_boundary_points(0, ymax, 0, tmax, int(Nb/4))\n",
    "\n",
    "    xb_up, tb_up = get_boundary_points(0, xmax, 0, tmax, int(Nb/4))\n",
    "    yb_up = np.ones(int(Nb/4))\n",
    "\n",
    "    xb_down, tb_down = get_boundary_points(0, xmax, 0, tmax, int(Nb/4))\n",
    "    yb_down = np.zeros(int(Nb/4))\n",
    "\n",
    "    xu, yu, tu, uu, vu, pu = get_training_data_batch(all_training_inputs, all_training_outputs, Nu)\n",
    "\n",
    "    xic, yic = get_initial_points(0, xmax, 0, ymax, Ni)\n",
    "\n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    xf_tensor = torch.tensor(xf, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    yf_tensor = torch.tensor(yf, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    tf_tensor = torch.tensor(tf, dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "    xc_tensor = torch.tensor(xc, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    yc_tensor = torch.tensor(yc, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    tc_tensor = torch.tensor(tc, dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "    xb_left_tensor = torch.tensor(xb_left, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    yb_left_tensor = torch.tensor(yb_left, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    tb_left_tensor = torch.tensor(tb_left, dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "    xb_right_tensor = torch.tensor(xb_right, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    yb_right_tensor = torch.tensor(yb_right, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    tb_right_tensor = torch.tensor(tb_right, dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "    xb_up_tensor = torch.tensor(xb_up, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    yb_up_tensor = torch.tensor(yb_up, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    tb_up_tensor = torch.tensor(tb_up, dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "    xb_down_tensor = torch.tensor(xb_down, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    yb_down_tensor = torch.tensor(yb_down, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    tb_down_tensor = torch.tensor(tb_down, dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "    xu_tensor = torch.tensor(xu, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    yu_tensor = torch.tensor(yu, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    tu_tensor = torch.tensor(tu, dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "    uu_tensor = torch.tensor(uu, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    vu_tensor = torch.tensor(vu, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    pu_tensor = torch.tensor(pu, dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "    xic_tensor = torch.tensor(xic, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    yic_tensor = torch.tensor(yic, dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "    return xf_tensor, yf_tensor, tf_tensor, xc_tensor, yc_tensor, tc_tensor, xb_left_tensor, yb_left_tensor, tb_left_tensor, xb_right_tensor, yb_right_tensor, tb_right_tensor, xb_up_tensor, yb_up_tensor, tb_up_tensor, xb_down_tensor, yb_down_tensor, tb_down_tensor, xu_tensor, yu_tensor, tu_tensor, uu_tensor, vu_tensor, pu_tensor, xic_tensor, yic_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nf = 1000\n",
    "# Nc = 4000\n",
    "# Nb = 4000\n",
    "# Nu = 5000\n",
    "# Ni = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_batch():\n",
    "\n",
    "    xf, yf, tf, xc, yc, tc, xb_left, yb_left, tb_left, xb_right, yb_right, tb_right, xb_up, yb_up, tb_up, xb_down, yb_down, tb_down, xic, yic = map(lambda x: x.detach(), get_batch(Nf, Nc, Nb, Nu, Ni))\n",
    "\n",
    "    xb = np.concatenate((xb_left.detach().numpy(), xb_right.detach().numpy(), xb_up.detach().numpy(), xb_down.detach().numpy()))\n",
    "    yb = np.concatenate((yb_left.detach().numpy(), yb_right.detach().numpy(), yb_up.detach().numpy(), yb_down.detach().numpy()))\n",
    "    tb = np.concatenate((tb_left.detach().numpy(), tb_right.detach().numpy(), tb_up.detach().numpy(), tb_down.detach().numpy()))\n",
    "\n",
    "    fig1 = go.Figure(\n",
    "        data = [\n",
    "                go.Scatter3d(\n",
    "                    x=xf,\n",
    "                    y=tf,\n",
    "                    z=yf,\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=2,\n",
    "                        color=\"blue\",\n",
    "                        colorscale='Viridis',\n",
    "                        opacity=0.8),\n",
    "                    name=\"Collocation points\",\n",
    "                    showlegend=True)])\n",
    "\n",
    "    fig2 = go.Figure(\n",
    "        data = [\n",
    "                go.Scatter3d(\n",
    "                    x=xb,\n",
    "                    y=tb,\n",
    "                    z=yb,\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=2,\n",
    "                        color=\"green\",\n",
    "                        colorscale='Viridis',\n",
    "                        opacity=0.8),\n",
    "                        name=\"Boundary points\",\n",
    "                        showlegend=True),\n",
    "                go.Scatter3d(\n",
    "                    x=xc,\n",
    "                    y=tc,\n",
    "                    z=yc,\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=2,\n",
    "                        color=\"red\",\n",
    "                        colorscale='Viridis',\n",
    "                        opacity=0.8),\n",
    "                    name=\"Cylinder boundary points\",\n",
    "                    showlegend=True),\n",
    "                go.Scatter3d(\n",
    "                    x=xic,\n",
    "                    y=np.zeros_like(xic),\n",
    "                    z=yic,\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=2,\n",
    "                        color=\"yellow\",\n",
    "                        colorscale='Viridis',\n",
    "                        opacity=0.8),\n",
    "                    name=\"Initial points\",\n",
    "                    showlegend=True)\n",
    "                    ])\n",
    "\n",
    "    # Updating titles and labels\n",
    "    for fig in [fig1, fig2]:\n",
    "        fig.update_layout(\n",
    "            scene=dict(\n",
    "                xaxis_title='x',\n",
    "                yaxis_title='t',\n",
    "                zaxis_title='y'\n",
    "            ),\n",
    "            width=700,\n",
    "            margin=dict(r=20, b=10, l=10, t=10))\n",
    "        # Show the plot\n",
    "        fig.show()\n",
    "\n",
    "# plot_batch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Neural Network with Skip Connections (FCNNskip)\n",
    "\n",
    "Note that the skip connection layers are created in parallel with the regular layers. In the forward pass, we add the output of the skip connection to the output of the regular layer, following the standard practice for implementing skip connections.\n",
    "\n",
    "In the loop that creates the layers, we create an extra \"skip\" layer every 2 layers, starting from the first layer. This layer has the same output size as the corresponding regular layer but always has an input size of 3 (the size of the input to the network). This is because the skip connections \"skip\" over the intervening layers and always connect back to the original input.\n",
    "\n",
    "In the forward pass, we create a separate skip_input tensor that we pass through the skip layers. This is because the regular input tensor is being modified by the regular layers, but we want the skip connections to always connect back to the original input.\n",
    "\n",
    "Then, every 2 layers, we add the output of the skip layer to the output of the regular layer before passing it through the activation function. This is the key feature of skip connections: they allow the network to learn an \"identity\" function that can bypass the intervening layers if necessary.\n",
    "\n",
    "Finally, note that the output layer does not have a corresponding skip layer, since it's the final layer in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "class PINN(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_units):\n",
    "\n",
    "        super(PINN, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        self.skip_layers = nn.ModuleList()  # for skip connections\n",
    "        in_units = 3\n",
    "        out_units = 3\n",
    "        \n",
    "        for i, units in enumerate(hidden_units):\n",
    "            layer = nn.Sequential(\n",
    "                nn.Linear(in_units, units),\n",
    "                nn.BatchNorm1d(units),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "            self.layers.append(layer)\n",
    "            in_units = units\n",
    "            # Create additional layers for skip connections\n",
    "            if i % 2 == 0:\n",
    "                skip_layer = nn.Sequential(\n",
    "                    nn.Linear(3, units),  # from input dimension to current hidden units\n",
    "                    nn.BatchNorm1d(units),\n",
    "                )\n",
    "                self.skip_layers.append(skip_layer)\n",
    "\n",
    "        output_layer = nn.Sequential(\n",
    "            nn.Linear(in_units, out_units),\n",
    "            nn.BatchNorm1d(out_units),\n",
    "        )\n",
    "        self.layers.append(output_layer)\n",
    "\n",
    "        # Initialize layers with Xavier initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x, y, t):\n",
    "\n",
    "        x = x.flatten()\n",
    "        y = y.flatten()\n",
    "        t = t.flatten()\n",
    "\n",
    "        input = torch.stack([x, y, t], dim=-1)\n",
    "        skip_input = input.clone()\n",
    "\n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            output = layer(input)\n",
    "            if i % 2 == 0 and i // 2 < len(self.skip_layers):  # apply skip connection every 2 layers\n",
    "                skip_output = self.skip_layers[i // 2](skip_input)\n",
    "                output = output + skip_output  # add skip connection output\n",
    "            input = output\n",
    "        output = self.layers[-1](input)\n",
    "        u = output[:, 0]\n",
    "        v = output[:, 1]\n",
    "        p = output[:, 2]\n",
    "\n",
    "        return u, v, p\n",
    "\n",
    "    def mse_f(self, x, y, t):\n",
    "\n",
    "        u, v, p = self(x, y, t)\n",
    "\n",
    "        # Compute derivatives of u\n",
    "        u_t = compute_grad(u, t)\n",
    "        u_x = compute_grad(u, x)\n",
    "        u_y = compute_grad(u, y)\n",
    "        u_xx = compute_grad(u_x, x)\n",
    "        u_yy = compute_grad(u_y, y)\n",
    "\n",
    "        # Compute derivatives of v\n",
    "        v_t = compute_grad(v, t)\n",
    "        v_x = compute_grad(v, x)\n",
    "        v_y = compute_grad(v, y)\n",
    "        v_xx = compute_grad(v_x, x)\n",
    "        v_yy = compute_grad(v_y, y)\n",
    "\n",
    "        # Compute derivatives of p\n",
    "        p_x = compute_grad(p, x)\n",
    "        p_xx = compute_grad(p_x, x)\n",
    "        p_y = compute_grad(p, y)\n",
    "        p_yy = compute_grad(p_y, y)\n",
    "\n",
    "        # Compute additional derivatives\n",
    "        u2_x = compute_grad(u**2, x)\n",
    "        v2_y = compute_grad(v**2, y)\n",
    "        uv_y = compute_grad(u*v, y)\n",
    "        uv_x = compute_grad(u*v, x)\n",
    "\n",
    "        f1 = u_x + v_y\n",
    "        f2 = rho * (u_t + u*u_x + v*u_y) + p_x - mu * (u_xx + u_yy)\n",
    "        f3 = rho * (v_t + u*v_x + v*v_y + p_y - mu * (v_xx + v_yy))\n",
    "        # f4 = p_xx + p_yy + rho * (u_x**2 - 2*u_y*v_x - v_y**2)\n",
    "        f4 = p_xx + p_yy + rho * (u2_x + uv_y + uv_x + v2_y)\n",
    "\n",
    "        _mse = (1/4) *  (torch.mean(torch.square(f1)) + \\\n",
    "                        torch.mean(torch.square(f2)) + \\\n",
    "                        torch.mean(torch.square(f3)) + \\\n",
    "                        torch.mean(torch.square(f4)))\n",
    "\n",
    "        return _mse\n",
    "\n",
    "    def mse_ic(self, x, y):\n",
    "        \n",
    "        t = torch.zeros_like(x)\n",
    "        u, v, p = self(x, y, t)\n",
    "\n",
    "        _mse = torch.mean( torch.square(u) + torch.square(v) + torch.square(p) )\n",
    "\n",
    "        return _mse\n",
    "\n",
    "    def mse_cylinder_bc(self, x, y, t):\n",
    "\n",
    "        u, v, p = self(x, y, t)\n",
    "\n",
    "        _mse = torch.mean( torch.square(u) + torch.square(v) )\n",
    "\n",
    "        return _mse\n",
    "\n",
    "    def mse_left_bc(self, y, t):\n",
    "\n",
    "        x = torch.zeros_like(y)\n",
    "        u, v, p = self(x, y, t)\n",
    "\n",
    "        _mse = torch.mean( torch.square(u - torch.ones_like(u)) + torch.square(v - torch.zeros_like(v)) )\n",
    "\n",
    "        return _mse\n",
    "\n",
    "    def mse_right_bc(self, y, t):\n",
    "\n",
    "        x = torch.full_like(y, xmax)\n",
    "        u, v, p = self(x, y, t)\n",
    "\n",
    "        u_t = compute_grad(u, t)\n",
    "        v_t = compute_grad(v, t)\n",
    "\n",
    "        _mse = torch.mean( torch.square(u_t) + torch.square(v_t) )\n",
    "\n",
    "        return _mse\n",
    "\n",
    "    def mse_up_bc(self, x, t):\n",
    "\n",
    "        y = torch.full_like(x, ymax)\n",
    "        u, v, p = self(x, y, t)\n",
    "\n",
    "        u_t = compute_grad(u, t)\n",
    "\n",
    "        _mse = torch.mean( torch.square(u_t) + torch.square(v) )\n",
    "\n",
    "        return _mse\n",
    "\n",
    "    def mse_down_bc(self, x, t):\n",
    "\n",
    "        y = torch.zeros_like(x)\n",
    "        u, v, p = self(x, y, t)\n",
    "\n",
    "        u_t = compute_grad(u, t)\n",
    "\n",
    "        _mse = torch.mean( torch.square(u_t) + torch.square(v) )\n",
    "\n",
    "        return _mse\n",
    "\n",
    "    def mse_bc(self, yb_left, tb_left, yb_right, tb_right, xb_up, tb_up, xb_down, tb_down):\n",
    "\n",
    "        _mse = (1/4) * (self.mse_left_bc(yb_left, tb_left) + self.mse_right_bc(yb_right, tb_right) + self.mse_up_bc(xb_up, tb_up) + self.mse_down_bc(xb_down, tb_down))\n",
    "\n",
    "        return _mse\n",
    "\n",
    "    def mse_u(self, xu, yu, tu, uu, vu, pu):\n",
    "\n",
    "        u, v, p = self(xu, yu, tu)\n",
    "\n",
    "        # _mse = (1/3) * (torch.mean(torch.square(uu - u)) + torch.mean(torch.square(vu - v)) + torch.mean(torch.square(pu - p)) )\n",
    "        _mse = (1/2) * (torch.mean(torch.square(uu - u)) + torch.mean(torch.square(vu - v)) )\n",
    "\n",
    "        return _mse\n",
    "\n",
    "    def loss(self, cf, cc, cb, cu, ci, xf, yf, tf, xc, yc, tc, xb_left, yb_left, tb_left, xb_right, yb_right, tb_right, xb_up, yb_up, tb_up, xb_down, yb_down, tb_down, xu, yu, tu, uu, vu, pu, xic, yic):\n",
    "        # unused values only for debugging\n",
    "\n",
    "        _mse_f = self.mse_f(xf, yf, tf)\n",
    "        _mse_cylinder_bc = self.mse_cylinder_bc(xc, yc, tc)\n",
    "        _mse_bc = self.mse_bc(yb_left, tb_left, yb_right, tb_right, xb_up, tb_up, xb_down, tb_down)\n",
    "        _mse_u = self.mse_u(xu, yu, tu, uu, vu, pu)\n",
    "        _mse_ic = self.mse_ic(xic, yic)\n",
    "\n",
    "        _loss = cf * _mse_f + cc * _mse_cylinder_bc +  cb * _mse_bc + cu * _mse_u + ci * _mse_ic\n",
    "        # _loss = cc * _mse_cylinder_bc +  cb * _mse_bc + cu * _mse_u\n",
    "\n",
    "        return _loss, _mse_f, _mse_cylinder_bc, _mse_bc, _mse_u, _mse_ic\n",
    "\n",
    "    def set_training_params(self, optimizer, cf, cc, cb, cu, ci, Nf, Nc, Nb, Nu, Ni):\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.cf = cf\n",
    "        self.cc = cc\n",
    "        self.cb = cb\n",
    "        self.cu = cu\n",
    "        self.ci = ci\n",
    "        self.Nf = Nf\n",
    "        self.Nc = Nc\n",
    "        self.Nb = Nb\n",
    "        self.Nu = Nu\n",
    "        self.Ni = Ni\n",
    "\n",
    "    def closure(self):\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        xf, yf, tf, xc, yc, tc, xb_left, yb_left, tb_left, xb_right, yb_right, tb_right, xb_up, yb_up, tb_up, xb_down, yb_down, tb_down, xu, yu, tu, uu, vu, pu, xic, yic = get_batch(self.Nf, self.Nc, self.Nb, self.Nu, self.Ni)\n",
    "\n",
    "        _loss, _, _, _, _, _ = self.loss(self.cf, self.cc, self.cb, self.cu, self.ci, xf, yf, tf, xc, yc, tc, xb_left, yb_left, tb_left, xb_right, yb_right, tb_right, xb_up, yb_up, tb_up, xb_down, yb_down, tb_down, xu, yu, tu, uu, vu, pu, xic, yic)\n",
    "        _loss.backward()\n",
    "\n",
    "        return _loss\n",
    "\n",
    "    def report_loss(self):\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        xf, yf, tf, xc, yc, tc, xb_left, yb_left, tb_left, xb_right, yb_right, tb_right, xb_up, yb_up, tb_up, xb_down, yb_down, tb_down , xu, yu, tu, uu, vu, pu, xic, yic = get_batch(self.Nf, self.Nc, self.Nb, self.Nu, self.Ni)\n",
    "        _loss, _mse_f, _mse_cylinder_bc, _mse_bc, _mse_u, _mse_ic = self.loss(self.cf, self.cc, self.cb, self.cu, self.ci, xf, yf, tf, xc, yc, tc, xb_left, yb_left, tb_left, xb_right, yb_right, tb_right, xb_up, yb_up, tb_up, xb_down, yb_down, tb_down, xu, yu, tu, uu, vu, pu, xic, yic)\n",
    "\n",
    "        return _loss, _mse_f, _mse_cylinder_bc, _mse_bc, _mse_u, _mse_ic\n",
    "\n",
    "\n",
    "    def train(self, epochs, optimizer, cf, cc, cb, cu, ci, Nf, Nc, Nb, Nu, Ni):\n",
    "\n",
    "        self.set_training_params(optimizer, cf, cc, cb, cu, ci, Nf, Nc, Nb, Nu, Ni)\n",
    "\n",
    "        self.training_inputs, self.training_outputs = load_training_data()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.step(self.closure)\n",
    "            if epoch % 10 == 0:\n",
    "                _loss, _mse_f, _mse_cylinder_bc, _mse_bc, _mse_u, _mse_ic = self.report_loss()\n",
    "                print(f'Epoch: {epoch},\\tTotal loss: {_loss},\\tPDE loss: {_mse_f},\\tCylinder BC loss: {_mse_cylinder_bc},\\tBC loss: {_mse_bc},\\tTraining data loss: {_mse_u},\\tIC loss: {_mse_ic}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Physical interpretation of the boundary conditions:\n",
    "\n",
    "1. `mse_left_bc`: On the left boundary of the fluid domain (x=0), the fluid has a horizontal velocity `u` of 1, and a vertical velocity `v` of 0. This suggests a fluid entering the domain from the left with a unit speed and flowing only in the horizontal direction, i.e., no upward or downward movement of fluid on this boundary. \n",
    "\n",
    "2. `mse_right_bc`: On the right boundary of the fluid domain (x=xmax), the time derivatives of `u` and `v` are set to zero. This means the fluid's horizontal and vertical velocities aren't changing with time. This could imply either a steady-state flow or the fluid exiting the domain without any acceleration or deceleration at the right boundary.\n",
    "\n",
    "3. `mse_up_bc`: On the top boundary of the fluid domain (y=ymax), the vertical velocity `v` is zero, meaning there's no fluid flowing out of or into the domain from the top. Additionally, the time derivative of the horizontal velocity `u` is zero, implying the horizontal movement of the fluid at this boundary is not changing over time.\n",
    "\n",
    "4. `mse_down_bc`: On the bottom boundary of the fluid domain (y=0), similar to `mse_up_bc`, the vertical velocity `v` is zero, implying no fluid flow into or out of the domain from the bottom. Also, the time derivative of the horizontal velocity `u` is zero, suggesting no change in horizontal movement over time at the bottom boundary.\n",
    "\n",
    "In short, these boundary conditions imply that fluid enters the domain from the left, moves horizontally without any vertical movement at the top and bottom boundaries, and exits from the right boundary without changing speed over time. Also, there's no fluid movement into or out of the domain from the top or bottom boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_units = [32, 32, 32]\n",
    "# hidden_units = [64, 64, 64, 64]\n",
    "# hidden_units = [128, 128, 128, 128]\n",
    "# hidden_units = [256, 256, 256, 256]\n",
    "# hidden_units = [512, 512]\n",
    "# hidden_units = [1024, 1024, 1024]\n",
    "# hidden_units = [20, 40, 80, 100, 100, 80, 40, 20]\n",
    "hidden_units = [128 for _ in range(20)]\n",
    "# hidden_units = [20, 20, 20, 20, 20, 20, 20, 20]\n",
    "# hidden_units = [100, 100, 100, 100, 100, 100]\n",
    "# hidden_units = [64 for _ in range(4)]\n",
    "\n",
    "pinn = PINN(hidden_units).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = torch.optim.Adam(pinn.parameters(), lr=0.001)\n",
    "# optimizer = torch.optim.LBFGS(pinn.parameters())\n",
    "# optimizer = torch.optim.LBFGS(pinn.parameters(), \n",
    "#                               lr=1, \n",
    "#                               max_iter=50000, \n",
    "#                               max_eval=50000, \n",
    "#                               tolerance_grad=1.0 * np.finfo(float).eps, \n",
    "#                               tolerance_change=1.0 * np.finfo(float).eps, \n",
    "#                               history_size=50,\n",
    "#                               line_search_fn='strong_wolfe')\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "cf = 0.01\n",
    "cc = 0.5\n",
    "cb = 0.1\n",
    "cu = 0.5\n",
    "ci = 0.5\n",
    "\n",
    "Nf = 1000\n",
    "Nc = 4000\n",
    "Nb = 4000\n",
    "Nu = 5000\n",
    "Ni = 4000\n",
    "\n",
    "pinn.train(epochs, optimizer, cf, cc, cb, cu, ci, Nf, Nc, Nb, Nu, Ni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pinn.state_dict(), './pinn4.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx = 100\n",
    "Ny = 100\n",
    "\n",
    "x_test = np.linspace(0, xmax, Nx)\n",
    "y_test = np.linspace(0, ymax, Ny)\n",
    "t_test = np.array([0.1])\n",
    "\n",
    "x_test_grid, y_test_grid, t_test_grid = np.meshgrid(x_test, y_test, t_test)\n",
    "\n",
    "# Evaluate the model at the grid points\n",
    "x_test_tensor = torch.tensor(x_test_grid.reshape(-1, 1), dtype=torch.float32, device=device, requires_grad=True)\n",
    "y_test_tensor = torch.tensor(y_test_grid.reshape(-1, 1), dtype=torch.float32, device=device, requires_grad=True)\n",
    "t_test_tensor = torch.tensor(t_test_grid.reshape(-1, 1), dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation to save memory and computation\n",
    "    u, v, p = pinn(x_test_tensor, y_test_tensor, t_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = u.detach().cpu().numpy().reshape(x_test.shape[0], y_test.shape[0])\n",
    "v = v.detach().cpu().numpy().reshape(x_test.shape[0], y_test.shape[0])\n",
    "p = p.detach().cpu().numpy().reshape(x_test.shape[0], y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "velocity_magnitude = np.sqrt(u**2 + v**2)\n",
    "\n",
    "x_test_grid_2d, y_test_grid_2d = np.meshgrid(x_test, y_test)\n",
    "\n",
    "strm = ax.streamplot(x_test_grid_2d, y_test_grid_2d, u, v, color=velocity_magnitude, linewidth=1, cmap=cm.inferno)\n",
    "\n",
    "ax.set_xlim(0, 1)  # Set x-axis limits\n",
    "ax.set_ylim(0, 1)  # Set y-axis limits\n",
    "ax.set_xlabel(\"x\")  # Set y-axis limits\n",
    "ax.set_ylabel(\"y\")  # Set y-axis limits\n",
    "\n",
    "norm = mcolors.Normalize(vmin=np.min(velocity_magnitude), vmax=np.max(velocity_magnitude))\n",
    "sm = plt.cm.ScalarMappable(cmap=cm.inferno, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "fig.colorbar(sm, ax=ax, label='Velocity magnitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_Nx = 100\n",
    "_Ny = 100\n",
    "\n",
    "x_test = np.linspace(0, xmax, _Nx)\n",
    "y_test = np.linspace(0, ymax, _Ny)\n",
    "\n",
    "u_all = np.array([])\n",
    "v_all = np.array([])\n",
    "p_all = np.array([])\n",
    "\n",
    "_Nt = 20\n",
    "_dt = tmax / (_Nt - 1)\n",
    "\n",
    "for t in np.arange(0., tmax + _dt/2, _dt):\n",
    "    _t = np.array([t])\n",
    "    \n",
    "    _x_test_grid, _y_test_grid, _t_test_grid = np.meshgrid(x_test, y_test, _t)\n",
    "\n",
    "    _x_test_tensor = torch.tensor(_x_test_grid.reshape(-1, 1), dtype=torch.float32, device=device, requires_grad=True)\n",
    "    _y_test_tensor = torch.tensor(_y_test_grid.reshape(-1, 1), dtype=torch.float32, device=device, requires_grad=True)\n",
    "    _t_test_tensor = torch.tensor(_t_test_grid.reshape(-1, 1), dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation to save memory and computation\n",
    "        _u, _v, _p = pinn(_x_test_tensor, _y_test_tensor, _t_test_tensor)\n",
    "        _u = _u.detach().cpu().numpy().reshape(x_test.shape[0], y_test.shape[0])\n",
    "        _v = _v.detach().cpu().numpy().reshape(x_test.shape[0], y_test.shape[0])\n",
    "        _p = _p.detach().cpu().numpy().reshape(x_test.shape[0], y_test.shape[0])\n",
    "        u_all = np.append(u_all, _u)\n",
    "        v_all = np.append(v_all, _v)\n",
    "        p_all = np.append(p_all, _p)\n",
    "\n",
    "u_all = u_all.reshape(_Nt, _Nx, _Ny)\n",
    "v_all = v_all.reshape(_Nt, _Nx, _Ny)\n",
    "p_all = p_all.reshape(_Nt, _Nx, _Ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x_test_grid, _y_test_grid = np.meshgrid(x_test, y_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "\n",
    "timestep = -1\n",
    "\n",
    "# Compute the velocity magnitude\n",
    "magnitude = np.sqrt(u_all[timestep]**2 + v_all[timestep]**2)\n",
    "\n",
    "# Plotting the velocity magnitude field\n",
    "contour = ax.contourf(_x_test_grid, _y_test_grid, magnitude, alpha=1, cmap=cm.plasma, levels=100)\n",
    "fig.colorbar(contour, ax=ax, label='Velocity magnitude')\n",
    "\n",
    "# Plotting the velocity field\n",
    "quiver = ax.quiver(_x_test_grid[::4, ::4], _y_test_grid[::4, ::4], u_all[timestep][::4, ::4], v_all[timestep][::4, ::4])\n",
    "\n",
    "# Plotting the cylinder\n",
    "# ax.scatter(X[cylinder], Y[cylinder], color='black', s=100)\n",
    "\n",
    "# Adding labels\n",
    "ax.set_xlabel('X Position')\n",
    "ax.set_ylabel('Y Position')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "\n",
    "# Adding labels\n",
    "ax.set_xlabel('X Position')\n",
    "ax.set_ylabel('Y Position')\n",
    "\n",
    "# Initialization function for the animation\n",
    "def init():\n",
    "    return []\n",
    "\n",
    "# Animation update function\n",
    "def update(num, u_data, v_data, p_data, X, Y, cylinder):\n",
    "    # Clear the current axes.\n",
    "    plt.cla()\n",
    "\n",
    "    # Compute the velocity magnitude for the current timestep\n",
    "    magnitude = np.sqrt(u_data[num]**2 + v_data[num]**2)\n",
    "    # magnitude = np.sqrt(p_data[num]**2)\n",
    "\n",
    "    # Create a new contour plot for the velocity magnitude\n",
    "    contour = ax.contourf(X, Y, magnitude, alpha=1, cmap=cm.plasma, levels=100)\n",
    "\n",
    "    # Create a new quiver plot for the velocity field\n",
    "    quiver = ax.quiver(X[::4, ::4], Y[::4, ::4], u_data[num][::4, ::4], v_data[num][::4, ::4])\n",
    "\n",
    "    # Create a new scatter plot for the cylinder\n",
    "    cylinder_plot = ax.scatter(X[cylinder], Y[cylinder], color='black', s=100)\n",
    "    # cylinder_plot = ax.scatter()\n",
    "\n",
    "    # Adding labels\n",
    "    ax.set_xlabel('X Position')\n",
    "    ax.set_ylabel('Y Position')\n",
    "\n",
    "    return contour, quiver, cylinder_plot,\n",
    "\n",
    "# Define the cylinder\n",
    "center = [0.5, 0.5]  # center of the cylinder\n",
    "radius = 0.1  # radius of the cylinder\n",
    "cylinder = np.sqrt((_x_test_grid - center[0])**2 + (_y_test_grid - center[1])**2) < radius\n",
    "\n",
    "# Create the animation\n",
    "ani = animation.FuncAnimation(fig, update, frames=range(len(u_all)), init_func=init, fargs=(u_all, v_all, p_all, _x_test_grid, _y_test_grid, cylinder), blit=False)\n",
    "\n",
    "# Create a ScalarMappable object\n",
    "norm = mcolors.Normalize(vmin=0, vmax=1)\n",
    "sm = plt.cm.ScalarMappable(cmap=cm.inferno, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "# Add a colorbar to the figure using the ScalarMappable object\n",
    "fig.colorbar(sm, ax=ax, label='Velocity magnitude')\n",
    "\n",
    "# Save the animation\n",
    "ani.save('flow_animation_pinn.gif', writer='pillow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
