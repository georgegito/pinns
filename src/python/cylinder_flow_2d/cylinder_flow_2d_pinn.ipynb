{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN for flow around a cylinder\n",
    "The Navier-Stokes equations are being solved for incompressible flow around a cylinder. These equations are a set of partial differential equations (PDEs) governing the motion of fluid substances. For a 2D incompressible, viscous flow, they can be written in the Cartesian coordinate system as follows:\n",
    "\n",
    "## Continuity Equation:\n",
    "\n",
    "The continuity equation represents the conservation of mass, stating that the mass entering a control volume must equal the mass exiting the volume, plus any change in mass within the volume. For an incompressible flow, it simplifies to:\n",
    "\n",
    "$$ \\nabla u = 0 $$\n",
    "\n",
    "or, in a two-dimensional form:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{\\partial u}{\\partial x} + \\frac{\\partial v}{\\partial y} = 0\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where u and v are the velocity components in the x and y directions respectively.\n",
    "\n",
    "## Momentum Equations:\n",
    "\n",
    "The momentum equations represent the conservation of momentum. They are the result of applying Newton's second law (force equals the rate of change of momentum) to fluid motion. The Navier-Stokes equations include the effects of viscosity, which are modeled with a Laplacian operator. The momentum equations for an incompressible flow can be written as:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\rho \\left( \\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x} + v \\frac{\\partial u}{\\partial y} \\right) = -\\frac{\\partial p}{\\partial x} + \\nu \\nabla^2 u\n",
    "\\tag{2}\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\rho \\left( \\frac{\\partial v}{\\partial t} + u \\frac{\\partial v}{\\partial x} + v \\frac{\\partial v}{\\partial y} \\right) = -\\frac{\\partial p}{\\partial y} + \\nu \\nabla^2 v\n",
    "\\tag{3}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "ρ is the fluid density\n",
    "u, v are the velocity components in the x and y directions, respectively\n",
    "t is time\n",
    "p is pressure\n",
    "ν is the kinematic viscosity\n",
    "∇² is the Laplacian operator, denoting the divergence of the gradient of a scalar field, here used to represent the diffusion of momentum (due to viscosity)\n",
    "The pressure-Poisson equation is also used to enforce incompressibility:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\nabla^2 p = -\\rho \\left( \\left( \\frac{\\partial u}{\\partial x} \\right)^2 + 2 \\frac{\\partial u}{\\partial y} \\frac{\\partial v}{\\partial x} + \\left( \\frac{\\partial v}{\\partial y} \\right)^2 \\right)\n",
    "\\tag{4}\n",
    "\\end{equation}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\nabla^2 p = \\frac{\\partial^2 p}{\\partial x^2} + \\frac{\\partial^2 p}{\\partial y^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmax = 1.0\n",
    "ymax = 1.0\n",
    "tmax = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 1\n",
    "mu = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cylinder\n",
    "center = [0.5, 0.5]  # center of the cylinder\n",
    "radius = 0.1  # radius of the cylinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad(x, y):\n",
    "        return torch.autograd.grad(x, y, grad_outputs=torch.ones_like(x), create_graph=True, retain_graph=True, only_inputs=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collocation_points(xmin, xmax, ymin, ymax, tmin, tmax, center, radius, n):\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    t = []\n",
    "\n",
    "    h, k = center  # center of the circle\n",
    "\n",
    "    while len(x) < n:  # generate Nf points\n",
    "        # Generate random point in the rectangle\n",
    "        x_point = xmin + (xmax - xmin) * random.random()\n",
    "        y_point = ymin + (ymax - ymin) * random.random()\n",
    "        t_point = tmin + (tmax - tmin) * random.random()\n",
    "        \n",
    "        # Check if point is outside the circle\n",
    "        if (x_point - h) ** 2 + (y_point - k) ** 2 >= radius ** 2:\n",
    "            x.append(x_point)\n",
    "            y.append(y_point)\n",
    "            t.append(t_point)\n",
    "    return x, y, t\n",
    "\n",
    "def get_boundary_points(xmin, xmax, tmin, tmax, n):\n",
    "    \n",
    "    x = []\n",
    "    t = []\n",
    "\n",
    "    while len(x) < n:  # generate Nb points\n",
    "    # Generate random point in the rectangle\n",
    "        x_point = xmin + (xmax - xmin) * random.random()\n",
    "        t_point = tmin + (tmax - tmin) * random.random()\n",
    "        \n",
    "        x.append(x_point)\n",
    "        t.append(t_point)\n",
    "\n",
    "    return x, t\n",
    "\n",
    "def get_cylinder_bc_points(center, radius, tmin, tmax, n):\n",
    "\n",
    "    x_center, y_center = center\n",
    "    x = []\n",
    "    y = []\n",
    "    t = []\n",
    "    \n",
    "    for _ in range(n):\n",
    "        # Generate random angle and random radius\n",
    "        rand_angle = 2 * math.pi * random.random()\n",
    "        rand_radius = radius * math.sqrt(random.random())\n",
    "        # Convert polar coordinates to cartesian\n",
    "        x_point = x_center + rand_radius * math.cos(rand_angle)\n",
    "        y_point = y_center + rand_radius * math.sin(rand_angle)\n",
    "        t_point = tmin + (tmax - tmin) * random.random()\n",
    "\n",
    "        # Append to the lists\n",
    "        x.append(x_point)\n",
    "        y.append(y_point)\n",
    "        t.append(t_point)\n",
    "\n",
    "    return x, y, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(Nf, Nc, Nb):\n",
    "\n",
    "    xf, yf, tf = get_collocation_points(0, xmax, 0, ymax, 0, tmax, center, radius, Nf)\n",
    "    xc, yc, tc = get_cylinder_bc_points(center, radius, 0, tmax, Nc)\n",
    "\n",
    "    xb_left = np.zeros(int(Nb/4))\n",
    "    yb_left, tb_left = get_boundary_points(0, ymax, 0, tmax, int(Nb/4))\n",
    "\n",
    "    xb_right = np.ones(int(Nb/4))\n",
    "    yb_right, tb_right = get_boundary_points(0, ymax, 0, tmax, int(Nb/4))\n",
    "\n",
    "    xb_up, tb_up = get_boundary_points(0, xmax, 0, tmax, int(Nb/4))\n",
    "    yb_up = np.ones(int(Nb/4))\n",
    "\n",
    "    xb_down, tb_down = get_boundary_points(0, xmax, 0, tmax, int(Nb/4))\n",
    "    yb_down = np.zeros(int(Nb/4))\n",
    "\n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    xf_tensor = torch.tensor(xf, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    yf_tensor = torch.tensor(yf, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    tf_tensor = torch.tensor(tf, dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "    xc_tensor = torch.tensor(xc, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    yc_tensor = torch.tensor(yc, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    tc_tensor = torch.tensor(tc, dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "    xb_left_tensor = torch.tensor(xb_left, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    yb_left_tensor = torch.tensor(yb_left, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    tb_left_tensor = torch.tensor(tb_left, dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "    xb_right_tensor = torch.tensor(xb_right, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    yb_right_tensor = torch.tensor(yb_right, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    tb_right_tensor = torch.tensor(tb_right, dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "    xb_up_tensor = torch.tensor(xb_up, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    yb_up_tensor = torch.tensor(yb_up, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    tb_up_tensor = torch.tensor(tb_up, dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "    xb_down_tensor = torch.tensor(xb_down, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    yb_down_tensor = torch.tensor(yb_down, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    tb_down_tensor = torch.tensor(tb_down, dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "    return xf_tensor, yf_tensor, tf_tensor, xc_tensor, yc_tensor, tc_tensor, xb_left_tensor, yb_left_tensor, tb_left_tensor, xb_right_tensor, yb_right_tensor, tb_right_tensor, xb_up_tensor, yb_up_tensor, tb_up_tensor, xb_down_tensor, yb_down_tensor, tb_down_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_units):\n",
    "\n",
    "        super(PINN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        in_units = 3\n",
    "        out_units = 3\n",
    "        for units in hidden_units:\n",
    "            layer = nn.Linear(in_units, units)\n",
    "            nn.init.xavier_normal_(layer.weight)\n",
    "            self.layers.append(layer)\n",
    "            in_units = units\n",
    "        output_layer = nn.Linear(in_units, out_units)\n",
    "        nn.init.xavier_normal_(output_layer.weight)\n",
    "        self.layers.append(output_layer)\n",
    "\n",
    "    def forward(self, x, y, t):\n",
    "\n",
    "        x = x.flatten()\n",
    "        y = y.flatten()\n",
    "        t = t.flatten()\n",
    "\n",
    "        input = torch.stack([x, y, t], dim=-1)\n",
    "\n",
    "        for layer in self.layers[:-1]:\n",
    "            output = torch.tanh(layer(input))\n",
    "            input = output\n",
    "        output = self.layers[-1](input)\n",
    "        u = output[:, 0]\n",
    "        v = output[:, 1]\n",
    "        p = output[:, 2]\n",
    "\n",
    "        return u, v, p\n",
    "\n",
    "    def mse_f(self, x, y, t):\n",
    "\n",
    "        u, v, p = self(x, y, t)\n",
    "\n",
    "        # Compute derivatives of u\n",
    "        u_t = compute_grad(u, t)\n",
    "        u_x = compute_grad(u, x)\n",
    "        u_y = compute_grad(u, y)\n",
    "        u_xx = compute_grad(u_x, x)\n",
    "        u_yy = compute_grad(u_y, y)\n",
    "\n",
    "        # Compute derivatives of v\n",
    "        v_t = compute_grad(v, t)\n",
    "        v_x = compute_grad(v, x)\n",
    "        v_y = compute_grad(v, y)\n",
    "        v_xx = compute_grad(v_x, x)\n",
    "        v_yy = compute_grad(v_y, y)\n",
    "\n",
    "        # Compute derivatives of p\n",
    "        p_x = compute_grad(p, x)\n",
    "        p_xx = compute_grad(p_x, x)\n",
    "        p_y = compute_grad(p, y)\n",
    "        p_yy = compute_grad(p_y, y)\n",
    "\n",
    "        f1 = u_x + v_y\n",
    "        f2 = rho * (u_t + u*u_x + v*u_y) + p_x - mu * (u_xx + u_yy)\n",
    "        f3 = rho * (v_t + u*v_x + v*v_y + p_y - mu * (v_xx + v_yy))\n",
    "        f4 = p_xx + p_yy + rho * (u_x**2 - 2*u_y*v_x - v_y**2)\n",
    "\n",
    "        _mse = (1/4) *  (torch.mean(torch.square(f1)) + \\\n",
    "                        torch.mean(torch.square(f2)) + \\\n",
    "                        torch.mean(torch.square(f3)) + \\\n",
    "                        torch.mean(torch.square(f4)))\n",
    "\n",
    "        return _mse\n",
    "    \n",
    "    def mse_ic(self):\n",
    "        return\n",
    "    \n",
    "    def mse_cylinder_bc(self, x, y, t):\n",
    "\n",
    "        u, v, p = self(x, y, t)\n",
    "\n",
    "        _mse = torch.mean( torch.square(u) + torch.square(v) )\n",
    "\n",
    "        return _mse\n",
    "    \n",
    "    def mse_left_bc(self, y, t):\n",
    "\n",
    "        x = torch.zeros_like(y)\n",
    "        u, v, p = self(x, y, t)\n",
    "\n",
    "        _mse = torch.mean( torch.square(u - torch.ones_like(u)) + torch.square(v - torch.zeros_like(v)) )\n",
    "\n",
    "        return _mse\n",
    "    \n",
    "    def mse_right_bc(self, y, t):\n",
    "\n",
    "        x = torch.full_like(y, xmax)\n",
    "        u, v, p = self(x, y, t)\n",
    "\n",
    "        u_t = compute_grad(u, t)\n",
    "        v_t = compute_grad(v, t)\n",
    "\n",
    "        _mse = torch.mean( torch.square(u_t) + torch.square(v_t) )\n",
    "\n",
    "        return _mse\n",
    "\n",
    "    def mse_up_bc(self, x, t):\n",
    "\n",
    "        y = torch.full_like(x, ymax)\n",
    "        u, v, p = self(x, y, t)\n",
    "\n",
    "        u_t = compute_grad(u, t)\n",
    "\n",
    "        _mse = torch.mean( torch.square(u_t) + torch.square(v) )\n",
    "\n",
    "        return _mse\n",
    "    \n",
    "    def mse_down_bc(self, x, t):\n",
    "\n",
    "        y = torch.zeros_like(x)\n",
    "        u, v, p = self(x, y, t)\n",
    "\n",
    "        u_t = compute_grad(u, t)\n",
    "\n",
    "        _mse = torch.mean( torch.square(u_t) + torch.square(v) )\n",
    "\n",
    "        return _mse\n",
    "\n",
    "    def mse_bc(self, yb_left, tb_left, yb_right, tb_right, xb_up, tb_up, xb_down, tb_down):\n",
    "\n",
    "        _mse = (1/4) * (self.mse_left_bc(yb_left, tb_left) + self.mse_right_bc(yb_right, tb_right) + self.mse_up_bc(xb_up, tb_up) + self.mse_down_bc(xb_down, tb_down))\n",
    "\n",
    "        return _mse\n",
    "\n",
    "    def mse_data():\n",
    "        # TODO\n",
    "        return\n",
    "\n",
    "    def loss(self, cf, cc, cb, xf, yf, tf, xc, yc, tc, xb_left, yb_left, tb_left, xb_right, yb_right, tb_right, xb_up, yb_up, tb_up, xb_down, yb_down, tb_down):\n",
    "        # unused values only for debugging\n",
    "\n",
    "        _mse_f = self.mse_f(xf, yf, tf)\n",
    "        _mse_cylinder_bc = self.mse_cylinder_bc(xc, yc, tc)\n",
    "        _mse_bc = self.mse_bc(yb_left, tb_left, yb_right, tb_right, xb_up, tb_up, xb_down, tb_down)\n",
    "\n",
    "        _loss = cf * _mse_f + cc * _mse_cylinder_bc +  cb * _mse_bc\n",
    "\n",
    "        return _loss, _mse_f, _mse_cylinder_bc, _mse_bc\n",
    "\n",
    "    def set_training_params(self, cf, cc, cb, Nf, Nc, Nb):\n",
    "\n",
    "        self.cf = cf\n",
    "        self.cc = cc\n",
    "        self.cb = cb \n",
    "        self.Nf = Nf\n",
    "        self.Nc = Nc\n",
    "        self.Nb = Nb\n",
    "\n",
    "    def closure(self, loss_report=False):\n",
    "\n",
    "        xf, yf, tf, xc, yc, tc, xb_left, yb_left, tb_left, xb_right, yb_right, tb_right, xb_up, yb_up, tb_up, xb_down, yb_down, tb_down = get_batch(self.Nf, self.Nc, self.Nb)\n",
    "        _loss, _mse_f, _mse_cylinder_bc, _mse_bc = self.loss(self.cf, self.cc, self.cb, xf, yf, tf, xc, yc, tc, xb_left, yb_left, tb_left, xb_right, yb_right, tb_right, xb_up, yb_up, tb_up, xb_down, yb_down, tb_down)\n",
    "\n",
    "        if loss_report:\n",
    "            return _loss, _mse_f, _mse_cylinder_bc, _mse_bc\n",
    "        else:\n",
    "            _loss.backward()\n",
    "            return _loss\n",
    "\n",
    "    def train(self, epochs, optimizer, cf, cc, cb, Nf, Nc, Nb):\n",
    "\n",
    "        self.set_training_params(cf, cc, cb, Nf, Nc, Nb)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.step(self.closure)\n",
    "            if epoch % 10 == 0:\n",
    "                _loss, _mse_f, _mse_cylinder_bc, _mse_bc = self.closure(loss_report=True)\n",
    "                print(f'Epoch: {epoch},\\tTotal loss: {_loss.item()},\\tPDE loss: {_mse_f.item()},\\tCylinder BC loss: {_mse_cylinder_bc.item()},\\tBC loss: {_mse_bc.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_units = [32, 32, 32]\n",
    "# hidden_units = [64, 64, 64, 64]\n",
    "# hidden_units = [128, 128, 128, 128]\n",
    "# hidden_units = [256, 256, 256, 256]\n",
    "# hidden_units = [512, 512]\n",
    "hidden_units = [1024, 1024, 1024]\n",
    "# hidden_units = [20, 40, 80, 100, 100, 80, 40, 20]\n",
    "# hidden_units = [32 for _ in range(20)]\n",
    "\n",
    "pinn = PINN(hidden_units).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(pinn.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.LBFGS(pinn.parameters())\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "cf = 0.05\n",
    "cc = 0.5\n",
    "cb = 0.5\n",
    "\n",
    "Nf = 100\n",
    "Nc = 1000\n",
    "Nb = 4000\n",
    "\n",
    "pinn.train(epochs, optimizer, cf, cc, cb, Nf, Nc, Nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nf = 10000\n",
    "# Nc = 1000\n",
    "# Nb = 4000\n",
    "\n",
    "# xf, yf, tf, xc, yc, tc, xb_left, yb_left, tb_left, xb_right, yb_right, tb_right, xb_up, yb_up, tb_up, xb_down, yb_down, tb_down = get_batch(Nf, Nc, Nb)\n",
    "\n",
    "# xb = np.concatenate((xb_left, xb_right, xb_up, xb_down))\n",
    "# yb = np.concatenate((yb_left, yb_right, yb_up, yb_down))\n",
    "# tb = np.concatenate((tb_left, tb_right, tb_up, tb_down))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "\n",
    "# fig1 = go.Figure(\n",
    "#     data = [\n",
    "#             go.Scatter3d(\n",
    "#                 x=xf,\n",
    "#                 y=tf,\n",
    "#                 z=yf,\n",
    "#                 mode='markers',\n",
    "#                 marker=dict(\n",
    "#                     size=2,\n",
    "#                     color=\"blue\",  # set color to z values for better visual understanding\n",
    "#                     colorscale='Viridis',  # choose a colorscale\n",
    "#                     opacity=0.8),\n",
    "#                 name=\"Collocation points\",\n",
    "#                 showlegend=True)])\n",
    "\n",
    "# fig2 = go.Figure(\n",
    "#     data = [\n",
    "#             go.Scatter3d(\n",
    "#                 x=xb,\n",
    "#                 y=tb,\n",
    "#                 z=yb,\n",
    "#                 mode='markers',\n",
    "#                 marker=dict(\n",
    "#                     size=2,\n",
    "#                     color=\"green\",  # set color to z values for better visual understanding\n",
    "#                     colorscale='Viridis',  # choose a colorscale\n",
    "#                     opacity=0.8),\n",
    "#                     name=\"Boundary points\",\n",
    "#                     showlegend=True),\n",
    "#             go.Scatter3d(\n",
    "#                 x=xc,\n",
    "#                 y=tc,\n",
    "#                 z=yc,\n",
    "#                 mode='markers',\n",
    "#                 marker=dict(\n",
    "#                     size=2,\n",
    "#                     color=\"red\",  # set color to z values for better visual understanding\n",
    "#                     colorscale='Viridis',  # choose a colorscale\n",
    "#                     opacity=0.8),\n",
    "#                 name=\"Cylinder boundary points\",\n",
    "#                 showlegend=True)])\n",
    "\n",
    "# # Updating titles and labels\n",
    "# for fig in [fig1, fig2]:\n",
    "#     fig.update_layout(\n",
    "#         scene=dict(\n",
    "#             xaxis_title='x',\n",
    "#             yaxis_title='t',\n",
    "#             zaxis_title='y'\n",
    "#         ),\n",
    "#         width=700,\n",
    "#         margin=dict(r=20, b=10, l=10, t=10))\n",
    "#     # Show the plot\n",
    "#     fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx = 100\n",
    "Ny = 100\n",
    "\n",
    "x_test = np.linspace(0, xmax, Nx)\n",
    "y_test = np.linspace(0, ymax, Ny)\n",
    "t_test = np.array([1])\n",
    "\n",
    "x_test_grid, y_test_grid, t_test_grid = np.meshgrid(x_test, y_test, t_test)\n",
    "\n",
    "# Evaluate the model at the grid points\n",
    "x_test_tensor = torch.tensor(x_test_grid.reshape(-1, 1), dtype=torch.float32, device=device, requires_grad=True)\n",
    "y_test_tensor = torch.tensor(y_test_grid.reshape(-1, 1), dtype=torch.float32, device=device, requires_grad=True)\n",
    "t_test_tensor = torch.tensor(t_test_grid.reshape(-1, 1), dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation to save memory and computation\n",
    "    u, v, p = pinn(x_test_tensor, y_test_tensor, t_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = u.detach().cpu().numpy().reshape(x_test.shape[0], y_test.shape[0])\n",
    "v = v.detach().cpu().numpy().reshape(x_test.shape[0], y_test.shape[0])\n",
    "p = p.detach().cpu().numpy().reshape(x_test.shape[0], y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "velocity_magnitude = np.sqrt(u**2 + v**2)\n",
    "\n",
    "x_test_grid_2d, y_test_grid_2d = np.meshgrid(x_test, y_test)\n",
    "\n",
    "strm = ax.streamplot(x_test_grid_2d, y_test_grid_2d, u, v, color=velocity_magnitude, linewidth=1, cmap=cm.inferno)\n",
    "\n",
    "ax.set_xlim(0, 1)  # Set x-axis limits\n",
    "ax.set_ylim(0, 1)  # Set y-axis limits\n",
    "ax.set_xlabel(\"x\")  # Set y-axis limits\n",
    "ax.set_ylabel(\"y\")  # Set y-axis limits\n",
    "\n",
    "norm = mcolors.Normalize(vmin=np.min(velocity_magnitude), vmax=np.max(velocity_magnitude))\n",
    "sm = plt.cm.ScalarMappable(cmap=cm.inferno, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "fig.colorbar(sm, ax=ax, label='Velocity magnitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_u_data(indices_to_extract, dir_path, Nt):\n",
    "\n",
    "    # Dictionary to store the results\n",
    "    result_dict = {}\n",
    "\n",
    "    for time_step in range(Nt):\n",
    "        file_path = dir_path + \"/u_\" + str(time_step) + \".csv\"\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            result_dict[file_path] = [df.iloc[i, j] for i, j in indices_to_extract]\n",
    "        else: \n",
    "            print(\"error\")\n",
    "            exit()\n",
    "\n",
    "    u_data = []\n",
    "\n",
    "    for file_path, values in result_dict.items():\n",
    "        u_data.append(values)\n",
    "\n",
    "    return np.array(u_data)\n",
    "\n",
    "def get_v_data(indices_to_extract, dir_path, Nt):\n",
    "\n",
    "    # Dictionary to store the results\n",
    "    result_dict = {}\n",
    "\n",
    "    for time_step in range(Nt):\n",
    "        file_path = dir_path + \"/v_\" + str(time_step) + \".csv\"\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            result_dict[file_path] = [df.iloc[i, j] for i, j in indices_to_extract]\n",
    "        else: \n",
    "            print(\"error\")\n",
    "            exit()\n",
    "\n",
    "    v_data = []\n",
    "\n",
    "    for file_path, values in result_dict.items():\n",
    "        v_data.append(values)\n",
    "\n",
    "    return np.array(v_data)\n",
    "\n",
    "def get_p_data(indices_to_extract, dir_path, Nt):\n",
    "\n",
    "    # Dictionary to store the results\n",
    "    result_dict = {}\n",
    "\n",
    "    for time_step in range(Nt):\n",
    "        file_path = dir_path + \"/p_\" + str(time_step) + \".csv\"\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            result_dict[file_path] = [df.iloc[i, j] for i, j in indices_to_extract]\n",
    "        else: \n",
    "            print(\"error\")\n",
    "            exit()\n",
    "\n",
    "    p_data = []\n",
    "\n",
    "    for file_path, values in result_dict.items():\n",
    "        p_data.append(values)\n",
    "\n",
    "    return np.array(p_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specified indices to extract\n",
    "data_indeces = [(10, 50), (10, 10), (50, 50), (50, 10)] # 0-based\n",
    "\n",
    "# Directory containing the CSV files\n",
    "u_data_dir_path = 'C:/Users/gitop/repos/pinns/src/python/cylinder_flow_2d/csv_files/u'\n",
    "v_data_dir_path = 'C:/Users/gitop/repos/pinns/src/python/cylinder_flow_2d/csv_files/v'\n",
    "p_data_dir_path = 'C:/Users/gitop/repos/pinns/src/python/cylinder_flow_2d/csv_files/p'\n",
    "\n",
    "# Number of timesteps\n",
    "Nt = 1000\n",
    "\n",
    "u_data = get_u_data(data_indeces, u_data_dir_path, Nt)\n",
    "v_data = get_v_data(data_indeces, v_data_dir_path, Nt)\n",
    "p_data = get_p_data(data_indeces, p_data_dir_path, Nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_coords(data_indeces, dx, dy):\n",
    "\n",
    "    coords = []\n",
    "\n",
    "    for x_index, y_index in data_indeces:\n",
    "        coords.append([x_index * dx, y_index * dy])\n",
    "\n",
    "    return coords\n",
    "\n",
    "def get_timestamps(Nt, dt):\n",
    "\n",
    "    timestamps = []\n",
    "\n",
    "    for timestep in range(Nt):\n",
    "        timestamps.append(timestep * dt)\n",
    "\n",
    "    return np.array(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmax = 1.0\n",
    "ymax = 1.0\n",
    "tmax = 0.1\n",
    "\n",
    "Nx = 64\n",
    "Ny = 64\n",
    "Nt = 1000\n",
    "\n",
    "dx = xmax / (Nx - 1)\n",
    "dy = ymax / (Ny - 1)\n",
    "dt = tmax / (Nt - 1)\n",
    "\n",
    "data_coords = get_data_coords(data_indeces, dx, dy)\n",
    "timestamps = get_timestamps(Nt, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.15873015873015872, 0.7936507936507936],\n",
       " [0.15873015873015872, 0.15873015873015872],\n",
       " [0.7936507936507936, 0.7936507936507936],\n",
       " [0.7936507936507936, 0.15873015873015872]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = []\n",
    "\n",
    "for t in timestamps:\n",
    "    for x, y in data_coords:\n",
    "        inputs.append([x, y, t])\n",
    "\n",
    "inputs = np.array(inputs)\n",
    "\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = []\n",
    "\n",
    "for t in range(Nt):\n",
    "    for i in range(len(data_coords)):\n",
    "        outputs.append([u_data[t, i], v_data[t, i], p_data[t, i]])\n",
    "\n",
    "outputs = np.array(outputs)\n",
    "outputs.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
