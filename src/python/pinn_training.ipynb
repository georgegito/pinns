{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics Informed Neural Networks <br> F1 Car Front Wing Aerodymanics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import csv\n",
    "from pinn import PINN\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = \"/Users/ggito/repos/pinns/data/\"\n",
    "points_filename = \"front_wing_points_final.csv\"\n",
    "norms_filename = \"front_wing_norms_final.csv\"\n",
    "\n",
    "out_dir = \"/Users/ggito/repos/pinns/data/\"\n",
    "models_out_dir = \"/Users/ggito/repos/pinns/data/models/\"\n",
    "log_filepath = out_dir + \"log/log.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wing_df = pd.read_csv(in_dir + points_filename)\n",
    "norm_df = pd.read_csv(in_dir + norms_filename)\n",
    "\n",
    "print(wing_df)\n",
    "print(norm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_max = 1\n",
    "y_max = 1\n",
    "z_max = 1\n",
    "t_max = 1\n",
    "\n",
    "Nx = 10\n",
    "Ny = 10\n",
    "Nz = 10\n",
    "Nt = 10\n",
    "\n",
    "dx = x_max / (Nx - 1)\n",
    "dy = y_max / (Ny - 1)\n",
    "dz = z_max / (Nz - 1)\n",
    "dt = t_max / (Nt - 1)\n",
    "\n",
    "x_test = np.linspace(0, x_max, Nx)\n",
    "y_test = np.linspace(0, y_max, Ny)\n",
    "z_test = np.linspace(0, z_max, Nz)\n",
    "t_test = np.linspace(0, t_max, Nt)\n",
    "\n",
    "x_grid, y_grid, z_gripd, t_grid = np.meshgrid(x_test, y_test, z_test, t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 4\n",
    "output_dim = 4\n",
    "# hidden_units = [32, 32, 32]\n",
    "# hidden_units = [64, 64, 64, 64]\n",
    "# hidden_units = [128, 128, 128, 128]\n",
    "# hidden_units = [256, 256, 256, 256]\n",
    "# hidden_units = [512, 512]\n",
    "# hidden_units = [1024, 1024, 1024]\n",
    "hidden_units = [1024, 1024, 1024, 1024]\n",
    "# hidden_units = [2048, 2048, 2048, 2048]\n",
    "# hidden_units = [20, 40, 80, 100, 100, 80, 40, 20]\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "  device = torch.device(\"mps\")\n",
    "  x = torch.ones(1, device=device)\n",
    "  print(x)\n",
    "else:\n",
    "  print(\"MPS device not found.\")\n",
    "  device = \"cpu\"\n",
    "\n",
    "# device = \"cpu\"\n",
    "\n",
    "pinn = PINN(input_dim, output_dim, hidden_units).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(pinn.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.LBFGS(pinn.parameters())\n",
    "\n",
    "epochs = 100\n",
    "Nf = 20000   # num of collocation points -> pde evaluation\n",
    "N0 = 20000   # num of points to evaluate initial conditons\n",
    "Nb = 20000   # num of points to evaluate boundary conditions\n",
    "Nw = 20000   # num of points of the surface of the front wing to evaluate boundary conditions\n",
    "\n",
    "# Density (rho): 1.2041kg/m^3\n",
    "# Dynamic viscosity (mu): 1.81e-5 kg/m.s\n",
    "rho = 1.2\n",
    "mu = 1.81e-5\n",
    "\n",
    "# m/s\n",
    "in_velocity = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_points_in_domain(min, max, num_of_samples):\n",
    "  return np.random.uniform(min, max, size=num_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeros(num):\n",
    "  return np.zeros(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ones(num):\n",
    "  return np.ones(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_inputs(x_max, y_max, z_max, t_max, Nf, N0, Nb, Nw):\n",
    "  # TODO: use quasi monte carlo sampling\n",
    "  # collocation points\n",
    "  x_f = utils.tensor_from_array(sample_points_in_domain(0, x_max, Nf), device=device, requires_grad=True)\n",
    "  y_f = utils.tensor_from_array(sample_points_in_domain(0, y_max, Nf), device=device, requires_grad=True)\n",
    "  z_f = utils.tensor_from_array(sample_points_in_domain(0, z_max, Nf), device=device, requires_grad=True)\n",
    "  t_f = utils.tensor_from_array(sample_points_in_domain(0, t_max, Nf), device=device, requires_grad=True)\n",
    "  # xyzt_f = utils.stack_xyzt_tensors(x_f, y_f, z_f, t_f)\n",
    "  # if stacked in a single tensor, the gradients are not computed correctly\n",
    "\n",
    "  # initial condition points (t=0)\n",
    "  x0 = utils.tensor_from_array(sample_points_in_domain(0, x_max, N0), device=device, requires_grad=False)\n",
    "  y0 = utils.tensor_from_array(sample_points_in_domain(0, y_max, N0), device=device, requires_grad=False)\n",
    "  z0 = utils.tensor_from_array(sample_points_in_domain(0, z_max, N0), device=device, requires_grad=False)\n",
    "  t0 = utils.tensor_from_array(zeros(N0), device=device, requires_grad=False)\n",
    "  xyzt_0 = utils.stack_xyzt_tensors(x0, y0, z0, t0)\n",
    "\n",
    "  # boundary condition points (inflow, y=1)\n",
    "  x_b = utils.tensor_from_array(sample_points_in_domain(0, x_max, Nb), device=device, requires_grad=False)\n",
    "  y_b = utils.tensor_from_array(ones(Nb), device=device, requires_grad=False)\n",
    "  z_b = utils.tensor_from_array(sample_points_in_domain(0, z_max, Nb), device=device, requires_grad=False)\n",
    "  t_b = utils.tensor_from_array(sample_points_in_domain(0, t_max, Nb), device=device, requires_grad=False)\n",
    "  xyzt_b = utils.stack_xyzt_tensors(x_b, y_b, z_b, t_b)\n",
    "\n",
    "  # points & normal vectors on the surface of the wing\n",
    "  ## sample Nw wing points with the corresponding normals\n",
    "  sampled_indices = wing_df.sample(n=Nw).index\n",
    "\n",
    "  x_w, y_w, z_w = [utils.tensor_from_array(wing_df.loc[sampled_indices, col].values, device=device, requires_grad=False) for col in ['x', 'y', 'z']]\n",
    "  n_x, n_y, n_z = [utils.tensor_from_array(norm_df.loc[sampled_indices, col].values, device=device, requires_grad=False) for col in ['x', 'y', 'z']]\n",
    "  t_w = utils.tensor_from_array(sample_points_in_domain(0, t_max, Nw), device=device, requires_grad=False)\n",
    "\n",
    "  xyzt_w = utils.stack_xyzt_tensors(x_w, y_w, z_w, t_w)\n",
    "  n_xyz = utils.stack_xyz_tensors(n_x, n_y, n_z)\n",
    "\n",
    "  return (x_f, y_f, z_f, t_f, xyzt_0, xyzt_b, xyzt_w, n_xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(pinn, models_out_dir + 'pinn10.pt')\n",
    "checkpoint_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure():\n",
    "\n",
    "  global epoch_loss\n",
    "\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  training_input = create_training_inputs(x_max, y_max, z_max, t_max, Nf, N0, Nb, Nw)\n",
    "\n",
    "  total_loss, pde_loss, ic_loss, bc_loss, no_slip_loss, imp_loss = pinn.loss(\n",
    "                  *training_input,\n",
    "                  in_velocity,\n",
    "                  mu, rho,\n",
    "                  c1=1, c2=1, c3=5, c4=1, c5=1)\n",
    "\n",
    "  epoch_loss = [total_loss.item(), pde_loss.item(), ic_loss.item(), bc_loss.item(), no_slip_loss.item(), imp_loss.item()]\n",
    "\n",
    "  total_loss.backward()\n",
    "\n",
    "  return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss = [0, 0, 0, 0, 0, 0]\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "  optimizer.step(lambda: closure())\n",
    "\n",
    "  utils.save_log(log_filepath, epoch, epoch_loss)\n",
    "  utils.print_log(epoch, epoch_loss)\n",
    "\n",
    "  # TODO\n",
    "  if np.isnan(epoch_loss[0]):\n",
    "    print(\"NaN loss, exiting...\")\n",
    "    break\n",
    "\n",
    "  if epoch % checkpoint_epochs == 0:\n",
    "    print(\"Saving checkpoint...\")\n",
    "    torch.save(pinn, models_out_dir + 'pinn12.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(pinn, model_out_dir + 'pinn10.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pinn = torch.load(model_out_dir + 'pinn8.pt')\n",
    "# pinn.train()\n",
    "# # loaded_model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
